include $JTESTS/hydraconfig/hydraparams1.inc;
include $JTESTS/hydraconfig/performance.inc;
include $JTESTS/hydraconfig/topology_3.inc;

hydra.GemFirePrms-conserveSockets = true;
hydra.GemFirePrms-distributedSystem =
      fcn "hydra.TestConfigFcns.duplicate(\"ds\",    ${feedHosts})" ncf
      fcn "hydra.TestConfigFcns.duplicate(\"ds\",    ${bridgeHosts})" ncf
      fcn "hydra.TestConfigFcns.duplicate(\"loner\", ${edgeHosts})" ncf
      ;
hydra.GemFirePrms-enableDurableClient =
      fcn "hydra.TestConfigFcns.duplicate(\"false\",      ${feedHosts})" ncf
      fcn "hydra.TestConfigFcns.duplicate(\"false\",      ${bridgeHosts})" ncf
      fcn "hydra.TestConfigFcns.duplicate(\"${durable}\", ${edgeHosts})" ncf
      ;
hydra.GemFirePrms-durableClientTimeout = 500;

hydra.VmPrms-extraVMArgs   = fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms750m -Xmx750m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC\", ${feedHosts}, true)"
                             ncf
                             ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms1600m -Xmx1600m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC\", ${bridgeHosts}, true)"
                             ncf
                             ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms512m -Xmx512m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC\", ${edgeHosts}, true)"
                             ncf;

THREADGROUP feed
    totalThreads = fcn
                   ${feedHosts} * ${feedVMsPerHost} * ${feedThreadsPerVM}
                   ncf          
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"feed\", ${feedHosts}, true)"     
                   ncf;
THREADGROUP bridge
    totalThreads = fcn
                   ${bridgeHosts} * ${bridgeVMsPerHost} * ${bridgeThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"bridge\", ${bridgeHosts}, true)"
                   ncf;
THREADGROUP edge
    totalThreads = fcn
                   ${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"edge\", ${edgeHosts}, true)"
                   ncf;                    

cacheperf.CachePerfPrms-batchTerminatorMethod     = terminateOnBatchSeconds;
cacheperf.CachePerfPrms-batchSeconds              = fcn ${workSeconds} + 1 ncf;
cacheperf.CachePerfPrms-warmupTerminatorMethod    = terminateOnTrimSeconds;
cacheperf.CachePerfPrms-warmupTerminatorFrequency = 5 seconds;
cacheperf.CachePerfPrms-trimSeconds               = ${trimSeconds};
cacheperf.CachePerfPrms-taskTerminatorMethod      = terminateOnTotalSeconds;
cacheperf.CachePerfPrms-taskTerminatorFrequency   = 15 seconds;
cacheperf.CachePerfPrms-workSeconds               = ${workSeconds};

hydra.Prms-testDescription = "Measure latency for hierarchical cache hosting a data feed pushing updates through to edges.  The feed updates replicated distributedNoAck bridge servers serving edges.  The cache contains ${totalBytes} bytes of data objects each of size ${dataSize} bytes.  The edges use thread local connections and register interest in ${interestPercentage}% of the keys, chosen randomly.";

hydra.Prms-totalTaskTimeSec = 259200;  // this test is workload based
hydra.Prms-maxResultWaitSec = 300;

cacheperf.CachePerfPrms-keyType = objects.BatchString;
objects.BatchStringPrms-batchSize = fcn (int)Math.ceil((${interestPercentage}/100.0) * (int)Math.ceil(${totalBytes}.0/${dataSize})) ncf;
cacheperf.CachePerfPrms-maxKeys = fcn (int)Math.ceil(${totalBytes}.0/${dataSize}) ncf;
cacheperf.CachePerfPrms-interestBatchSize = 1000;

cacheperf.comparisons.dataFeed.DataFeedPrms-useFixedKeys = ${useFixedKeys};
cacheperf.comparisons.dataFeed.DataFeedPrms-useFixedVal  = ${useFixedVal};
cacheperf.comparisons.dataFeed.DataFeedPrms-throttledOpsPerSec = 10;

hydra.BridgePrms-names                = bridge;

hydra.PoolPrms-names                  = pool;
hydra.PoolPrms-readTimeout            = 10000000;
hydra.PoolPrms-subscriptionEnabled    = true;
hydra.PoolPrms-threadLocalConnections = true;

hydra.CachePrms-names  = feed bridge edge;

hydra.RegionPrms-names                  = feed      bridge    edge;
hydra.RegionPrms-cacheListeners         = none,     none,
                 cacheperf.gemfire.LatencyListener;
hydra.RegionPrms-dataPolicy             = empty     replicate normal;
hydra.RegionPrms-enableSubscriptionConflation = default   false     default;
hydra.RegionPrms-poolName               = none      none      pool;
hydra.RegionPrms-scope                  = default   default   local;

INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openStatisticsTask
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = bridge
          hydra.ConfigPrms-regionConfig = bridge
          hydra.ConfigPrms-bridgeConfig = bridge
          threadGroups = bridge
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = feed
          hydra.ConfigPrms-regionConfig = feed
          threadGroups = feed
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          distcache.gemfire.GemFireCachePrms-interestResultPolicy = none
          hydra.ConfigPrms-cacheConfig = edge
          hydra.ConfigPrms-regionConfig = edge
          threadGroups = edge
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = registerInterestRegexTask
          cacheperf.CachePerfPrms-registerDurableInterest = ${durable}
          threadGroups = edge
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = createDataTask
          batch
          cacheperf.CachePerfPrms-keyAllocation = ownKeys
          cacheperf.CachePerfPrms-warmupTerminatorMethod = none
          cacheperf.CachePerfPrms-taskTerminatorMethod = terminateOnMaxKey
          cacheperf.CachePerfPrms-taskTerminatorFrequency = 1 iterations
          threadGroups = feed
          ;
TASK      taskClass = cacheperf.comparisons.dataFeed.DataFeedClient taskMethod = feedDataTask
          cacheperf.CachePerfPrms-keyAllocation = ownKeysRandomWrap
          threadGroups = feed
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeCacheTask
          threadGroups = feed, edge
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeCacheTask
          threadGroups = bridge
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeStatisticsTask;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = reportTrimIntervalsTask;
ENDTASK   taskClass = cacheperf.CachePerfClient taskMethod = openStatisticsTask
          clientNames = feed1;
ENDTASK   taskClass = cacheperf.comparisons.dataFeed.DataFeedClient taskMethod = validateMessagesFailedQueuedTask
          clientNames = feed1;
ENDTASK   taskClass = cacheperf.CachePerfClient taskMethod = closeStatisticsTask
          clientNames = feed1;

cacheperf.CachePerfPrms-objectType      = objects.ArrayOfByte;
objects.ArrayOfBytePrms-size            = ${dataSize};
objects.ArrayOfBytePrms-encodeTimestamp = true;

perffmwk.PerfReportPrms-statisticsSpecification = $JTESTS/cacheperf/gemfire/specs/putupdateEvents.spec;
