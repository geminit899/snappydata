INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/performance.inc;
INCLUDE $JTESTS/hydraconfig/topology_2.inc;

hydra.Prms-testDescription = "Replicated distributed region visible to p2p publishers and subscribers.  Each member overflows to disk using the new persistence implementation.  Members are configured with about 1GB of memory for the data region.  The data region size is about 50 GB.  Data regions are persistent and hence recoverable.  Publishers first concurrently create objects, then concurrently update objects.  The update keys must be randomly chosen.  Publishers create 50 GB data during the initialization phase of the test, then do the updates in the main workload for about 10 minutes.";

hydra.Prms-testRequirement =
"Put and get rates at least 3X better than the performance of 4.1.2";

THREADGROUP pub
    totalThreads = fcn
                   ${pubHosts} * ${pubVMsPerHost} * ${pubThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"pub\", ${pubHosts}, true)"
                   ncf;
THREADGROUP sub
    totalThreads = fcn
                   ${subHosts} * ${subVMsPerHost} * ${subThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"sub\", ${subHosts}, true)"
                   ncf;

INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openStatisticsTask
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = pub
          hydra.ConfigPrms-regionConfig = pub
          threadGroups = pub
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = sub
          hydra.ConfigPrms-regionConfig = sub
          threadGroups = sub
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = createDataTask
          threadGroups = pub
          batch
          cacheperf.CachePerfPrms-keyAllocation = ownKeys
          cacheperf.CachePerfPrms-warmupTerminatorMethod = none
          cacheperf.CachePerfPrms-taskTerminatorMethod = terminateOnMaxKey
          cacheperf.CachePerfPrms-taskTerminatorFrequency = 1 iterations
          ;
TASK      taskClass = cacheperf.CachePerfClient taskMethod = putDataTask
          threadGroups = pub
          cacheperf.CachePerfPrms-keyAllocation = ownKeysRandomWrap
          cacheperf.CachePerfPrms-warmupTerminatorMethod = terminateOnTrimSeconds
          cacheperf.CachePerfPrms-warmupTerminatorFrequency = 30 seconds
          cacheperf.CachePerfPrms-taskTerminatorMethod = terminateOnTotalSeconds
          cacheperf.CachePerfPrms-taskTerminatorFrequency = 30 seconds
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeCacheTask
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeStatisticsTask
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = reportTrimIntervalsTask
          ;

hydra.CachePrms-names = pub sub;

hydra.RegionPrms-names = pub sub;
hydra.RegionPrms-scope = ack;
hydra.RegionPrms-cacheListeners =
      none, cacheperf.gemfire.LatencyListener;
hydra.RegionPrms-diskStoreName = disk;
hydra.RegionPrms-diskSynchronous = ${synchronous};
hydra.RegionPrms-evictionAttributes =
      lruMemorySize ${evictionLimit} objects.PSTObject overflowToDisk;
hydra.RegionPrms-dataPolicy = persistentReplicate;

hydra.DiskStorePrms-names = disk;
hydra.DiskStorePrms-diskDirNum = 4;

hydra.GemFirePrms-distributedSystem = ds;
hydra.GemFirePrms-conserveSockets = true;

cacheperf.CachePerfPrms-batchTerminatorMethod = terminateOnBatchSeconds;
cacheperf.CachePerfPrms-batchSeconds = 120;
cacheperf.CachePerfPrms-trimSeconds  = 180;
cacheperf.CachePerfPrms-workSeconds  = 420;

hydra.Prms-totalTaskTimeSec = 999999; // see terminators

// keys/values
cacheperf.CachePerfPrms-objectType = objects.PSTObject;
cacheperf.CachePerfPrms-maxKeys    = ${maxKeys};
objects.PSTObjectPrms-size         = ${dataSize};

hydra.VmPrms-extraVMArgs =
     -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+PrintGCDetails;
hydra.VmPrms-extraVMArgs += -Xms2g -Xmx6g;
hydra.VmPrms-extraVMArgs += "-XX:CMSInitiatingOccupancyFraction=33";

perffmwk.PerfReportPrms-statisticsSpecification = $JTESTS/cacheperf/comparisons/diskRegion/diskRegion.spec;

//------------------------------------------------------------------------------
// CLOCK SKEW MANAGEMENT
//------------------------------------------------------------------------------
hydra.timeserver.TimeServerPrms-clockSkewUpdateFrequencyMs = 1000;
hydra.timeserver.TimeServerPrms-clockSkewThresholdMs = 1000;
hydra.timeserver.TimeServerPrms-errorOnExceededClockSkewThreshold = true;
