include $JTESTS/hydraconfig/hydraparams1.inc;
include $JTESTS/hydraconfig/systemparamsN.inc;
include $JTESTS/util/randomValues.inc;

hydra.ClientPrms-vmQuantities = 1;
hydra.ClientPrms-vmThreads    = 2;

THREADGROUP txThread    totalThreads = 1  totalVMs = 1 clientNames=client1;
THREADGROUP txValidator totalThreads = 1  totalVMs = 1 clientNames=client1;
THREADGROUP validator   totalThreads = 1  totalVMs = 1 clientNames=client2
                        totalThreads = 1  totalVMs = 1 clientNames=client3;
THREADGROUP killer_2    totalThreads = 1  totalVMs = 1 clientNames=client2;
THREADGROUP killer_3    totalThreads = 1  totalVMs = 1 clientNames=client3;

// establish empty data policy in transactional peer
STARTTASK  taskClass   = tx.TxUtil   taskMethod = StartTask_initialize
           clientNames = client1
           ;

INITTASK  taskClass   = tx.TxViewUtil taskMethod = HydraTask_createRegionForest
          ;
                                                                                
INITTASK  taskClass   = tx.ViewTest taskMethod = HydraTask_initialize
          ;

TASK      taskClass   = tx.ViewTest taskMethod = HydraTask_executeTx
          maxTimesToRun = 2
          threadGroups = txThread
          ;

TASK      taskClass   = tx.ViewTest taskMethod = HydraTask_killCommittor
          weight = 100
          maxTimesToRun=1
          threadGroups = killer_2
          ;

TASK      taskClass   = tx.ViewTest taskMethod = HydraTask_killCommittor
          weight = 100
          maxTimesToRun=1
          threadGroups = killer_3
          ;

TASK      taskClass   = tx.ViewTest taskMethod = HydraTask_waitForDist
          weight = 1
          threadGroups = txValidator, validator
          ;

CLOSETASK taskClass   = tx.ViewTest taskMethod = HydraCloseTask_validateTxConsistency
          threadGroups = txValidator, validator
          ;

// Note that this must come AFTER validateTxConsistency since we'll perform
// operations on the same keys as the previous transaction (which would 
// cause the data consistency validation to fail.  Only one VM can execute
// this since we'll be applying the same changes as the original commit
CLOSETASK taskClass   = tx.ViewTest taskMethod = HydraCloseTask_verifyResourcesReleased
          threadGroups = validator
          ;

hydra.Prms-totalTaskTimeSec = 600;
hydra.Prms-maxResultWaitSec = 360;
hydra.Prms-serialExecution=false;
hydra.Prms-alwaysDoEndTasks = true;

hydra.log.LogPrms-mergeLogFiles = true;

util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = 10000;
util.RandomValuesPrms-objectDepth = 0;
util.ValueHolderPrms-useExtraObject = true;

tx.TxPrms-commitStateTrigger = ${commitStateTrigger};
tx.TxPrms-killRemoteTxVm = true;

tx.TxPrms-commitPercentage=100;

tx.TxPrms-maxKeys=10;
tx.TxPrms-numRootRegions=2;
tx.TxPrms-numSubRegions=3;
tx.TxPrms-regionDepth=2;

hydra.ConfigPrms-cacheConfig    = myCache;
hydra.ConfigPrms-regionConfig   = myRegion;
hydra.CachePrms-names           = myCache;
hydra.RegionPrms-names          = myRegion;
hydra.RegionPrms-regionName     = TestRegion;
hydra.RegionPrms-cacheListeners = tx.LogListener;
hydra.RegionPrms-cacheLoader    = tx.TxLoader;
hydra.RegionPrms-scope          = ack;
hydra.RegionPrms-dataPolicy     = replicate;

tx.TxPrms-txListener = tx.TxViewListener;

tx.TxPrms-operations =
          entry-create entry-update entry-destroy entry-inval
          entry-create entry-update entry-destroy entry-inval
          entry-create entry-update entry-destroy entry-inval
          entry-create entry-update entry-destroy entry-inval
          ;

tx.TxPrms-numOps = RANGE 1 5 EGNAR;
tx.TxPrms-updateStrategy = ONEOF useCopyOnRead useCopyHelper FOENO; 


// We have to be careful not to do 'gets' from our empty client, as get will
// always do a load (since empty clients have no local storage).
tx.TxPrms-operations =
          entry-create entry-update entry-destroy entry-inval
          entry-create entry-update entry-destroy entry-inval
          entry-create entry-update entry-destroy entry-inval
          entry-create entry-update entry-destroy entry-inval
          //region-create
          ;

// We need to use replicated dataPolicies for validators, so that creates 
// will be distributed to each validator VM.  (client1 is the txThread)
tx.TxPrms-viewDataPolicies = empty-replicate-replicate;
