hydra.Prms-testRequirement = "Test partitioned regions with a variety of operations with careful validation and concurrent execution";
hydra.Prms-testDescription = "
This test executes operations on entries on a PartitionedRegion and carefully
validates for correctness. The data store for the partitioned region is spread
across all VMs. A network partition during the test should not cause a loss of data.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2_locator.inc;

STARTTASK    taskClass   = splitBrain.SplitBrainBB taskMethod = HydraTask_initialize 
             clientNames = losingSide1;

STARTTASK    taskClass   = splitBrain.SplitBrainBB taskMethod = postSelfAsLosingSideHost 
             clientNames = losingSide1;

//------------------------------------------------------------------------------
// INITIALIZATION WORK (configure locators)
//------------------------------------------------------------------------------

/**
 * Starts the locator and connects to admin-only distributed systems.
 */
INITTASK taskClass = splitBrain.SBUtil taskMethod = createLocatorTask
         threadGroups = locator;

INITTASK taskClass = splitBrain.SBUtil taskMethod = startAndConnectLocatorTask
         threadGroups = locator;

// Ensure leadMember is on the survivingSide
INITTASK taskClass   = splitBrain.PRNetDownTest  taskMethod = HydraTask_initialize
         threadGroups = survivingSide;

INITTASK taskClass   = splitBrain.PRNetDownTest  taskMethod = HydraTask_initialize
         threadGroups = losingSide;

TASK     taskClass   = splitBrain.PRNetDownTest  taskMethod = HydraTask_doConcOpsAndVerify
         threadGroups = survivingSide;

TASK     taskClass = rebalance.RebalanceTest taskMethod = HydraTask_rebalanceTask
         rebalance.RebalancePrms-resourceObserver = rebalance.NetDownResourceObserver
         startInterval = 231
         maxTimesToRun = 1
         rebalance.RebalancePrms-verifyBalance = false
         threadGroups = survivingSide;

CLOSETASK taskClass = rebalance.RebalanceTest taskMethod = HydraTask_rebalanceTask
         rebalance.RebalancePrms-verifyBalance = true
         threadGroups = survivingSide;

CLOSETASK taskClass = splitBrain.SBUtil taskMethod = restoreConnection
          threadGroups = locator;

CLOSETASK taskClass = splitBrain.NetworkPartitionTest taskMethod = closeCacheAndDisconnectFromDS
          threadGroups = survivingSide;

//ENDTASK   taskClass = splitBrain.NetworkPartitionTest taskMethod = HydraEndTask_verifyLosingPartition
          //clientNames = client1
          //;

THREADGROUP locator
    totalThreads = fcn ${locatorHosts} * ${locatorVMsPerHost}
                                       * ${locatorThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"locator\", ${locatorHosts}, true)"
                   ncf;
THREADGROUP ${A}
    totalThreads = fcn ${${A}Hosts} * ${${A}VMsPerHost}
                                    * ${${A}ThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"${A}\", ${${A}Hosts}, true)"
                   ncf;
THREADGROUP ${B}
    totalThreads = fcn ${${B}Hosts} * ${${B}VMsPerHost}
                                    * ${${B}ThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"${B}\", ${${B}Hosts}, true)"
                   ncf;

hydra.GemFirePrms-enableNetworkPartitionDetection = true;
hydra.GemFirePrms-disableAutoReconnect = true;
splitBrain.SplitBrainPrms-hostDescription1 = "survivingSidehost1";
splitBrain.SplitBrainPrms-hostDescription2 = "losingSidehost1";
splitBrain.SplitBrainPrms-dropWaitTimeSec = 60;

hydra.GemFirePrms-stopSystemsAfterTest = true;

// parReg.ParRegPrms-secondsToRun determines the running length rather than 
// totalTaskTimeSec because of the test's pausing scheme; without this the
// test could hang 
hydra.Prms-totalTaskTimeSec = 31536000;  
hydra.Prms-maxResultWaitSec = 600;
hydra.Prms-serialExecution = false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = 500;
util.ValueHolderPrms-useExtraObject = true;
hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

hydra.Prms-useFixedRandomInMaster= true;
hydra.RegionPrms-names          = clientRegion;
hydra.RegionPrms-regionName     = partitionedRegion;
hydra.RegionPrms-dataPolicy     = partition;
hydra.RegionPrms-partitionName  = pr;

hydra.PartitionPrms-names           = pr;
hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-recoveryDelay = 0;  // IMMEDIATE on member departure

util.CachePrms-useDeclarativeXmlFile = ONEOF true false FOENO;

util.TestHelperPrms-minTaskGranularitySec = 45;

// Don't allow write ops in the servers (dataStores) since this
// will lead to 39061 when ForcedDisconnect occurs
parReg.ParRegPrms-designateOps = true;
parReg.ParRegPrms-accessorOperations =
    ONEOF add putAll add putAll add putAll getNew getNew update get destroy putIfAbsent remove replaceNoInval replaceOldNoInval FOENO;
parReg.ParRegPrms-dataStoreOperations = ONEOF get get get get getNew FOENO;
parReg.ParRegPrms-upperThreshold = 500;
parReg.ParRegPrms-upperThresholdAccessorOperations = ONEOF destroy remove FOENO;
parReg.ParRegPrms-upperThresholdDataStoreOperations = ONEOF get replaceAsNoop replaceOldAsNoop FOENO;
parReg.ParRegPrms-lowerThreshold = 10;
parReg.ParRegPrms-lowerThresholdAccessorOperations = ONEOF add putAll putIfAbsentAsCreate FOENO;
parReg.ParRegPrms-lowerThresholdDataStoreOperations = ONEOF get replaceAsNoop replaceOldAsNoop FOENO;

parReg.ParRegPrms-entryOperations = notUsed;
parReg.ParRegPrms-lowerThresholdOperations = notUsed;
parReg.ParRegPrms-upperThresholdOperations = notUsed;

parReg.ParRegPrms-secondsToRun = 600;
