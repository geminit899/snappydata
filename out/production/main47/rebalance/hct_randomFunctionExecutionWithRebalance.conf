hydra.Prms-testDescription = "This test extends the parReg/execute/hct_randomFunctionExecution test by adding rebalancing (concurrently with the function execution TASKS).
This is a client server test with replicated regions and co-located partitioned regions.
The test does function executions on replicated regions, partitioned regions and also on servers.
This test does a set of random function executions with/without filter,
args and result collector. The test also does multiple function executions with
single/multiple data sets. Test then validates the results of each function execution
results.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_hct_2_locator.inc;

// one verify thread per datastore (but not accessor) vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost})" ncf
            totalVMs     = fcn "(${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"dataStorebridge\", 
                                ${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost}, true)" ncf;

// registerInterest threads (one thread per client VM)
THREADGROUP registerInterestThreads
            totalThreads = fcn "(${edgeHosts} * ${edgeVMsPerHost})" ncf
            totalVMs     = fcn "(${edgeHosts} * ${edgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"edge\", 
                                ${edgeHosts} * ${edgeVMsPerHost}, true)" ncf;

// accessorThreads are all threads in the accessor VMs 
THREADGROUP accessorVMThreads 
            totalThreads = fcn "(${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM})
                                 - (${edgeHosts} * ${edgeVMsPerHost})" ncf
            totalVMs     = fcn "(${edgeHosts} * ${edgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"edge\", 
                                ${edgeHosts} * ${edgeVMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost} * ${dataStorebridgeThreadsPerVM}) 
                               - (${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost}) ncf  
            totalVMs     = fcn ${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"dataStorebridge\", 
                                ${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost}, true)" ncf;

THREADGROUP locator
    totalThreads = fcn ${locatorHosts} * ${locatorVMsPerHost}
                                       * ${locatorThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"locator\", ${locatorHosts}, true)"
                   ncf;

THREADGROUP rebalance totalThreads = 1 totalVMs = 1 clientNames  = rebalancebridge1;

STARTTASK    taskClass     = parReg.execute.FunctionServiceTest  taskMethod = StartTask_initialize;

/**
 * Starts the locator and connects to admin-only distributed systems.
 */
INITTASK     taskClass = rebalance.RebalanceUtil taskMethod = createLocatorTask
             threadGroups = locator;

INITTASK     taskClass = rebalance.RebalanceUtil taskMethod = startAndConnectLocatorTask
             threadGroups = locator;

INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_HA_dataStoreInitialize
             threadGroups = dataStoreVMThreads;

INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_loadRegions
             threadGroups = dataStoreVMThreads
             batch
             ;
             
INITTASK      taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_waitForEventsReceival
             threadGroups = dataStoreVMThreads;             

INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

             
INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_verifyRegionSize
             threadGroups = verifyThreads
             ;  
             
INITTASK    taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_putKeySetInBB
             threadGroups = verifyThreads
			 ;              

// late initialization of rebalance (to create work for rebalancer)
INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_HA_dataStoreInitialize 
             threadGroups = rebalance;

// initialize accessors late, so that they will find the rebalancer's bridge endpoints
INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_HA_accessorInitialize
             threadGroups = registerInterestThreads;

INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_registerInterest
             threadGroups = registerInterestThreads;

INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_initRegisterFunction
             threadGroups = registerInterestThreads, dataStoreVMThreads, rebalance
             ;
                          
// Account for the extra (rebalancer) dataStore (even though no buckets are stored there until rebalanceTask is executed)
INITTASK     taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_incPR_TOTAL_DATASTORES
             threadGroups = rebalance;

TASK         taskClass   = rebalance.RebalanceTest taskMethod = HydraTask_rebalanceTask
             rebalance.RebalancePrms-verifyBalance = false
             threadGroups = rebalance
             ;
             
TASK         taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_doFireAndForgetExecutions
             threadGroups = accessorVMThreads, registerInterestThreads
             weight = 500;                       
 
TASK         taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_doRandomFunctionExecutions
             threadGroups = accessorVMThreads, registerInterestThreads
             weight = 2000;
             
TASK         taskClass     = parReg.execute.FunctionServiceTest  taskMethod = HydraTask_doRandomMemberFunctionExecutions
             threadGroups = accessorVMThreads, registerInterestThreads
             weight = 500;             

CLOSETASK    taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_verifyBucketCopies
             threadGroups = verifyThreads
             ;

CLOSETASK    taskClass     = parReg.execute.FunctionServiceTest  taskMethod  = HydraTask_verifyColocatedRegions
             threadGroups = verifyThreads;

                       
hydra.Prms-totalTaskTimeSec = 200; // test is workload based
hydra.Prms-maxResultWaitSec = 1500;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ONEOF 50 100 500 1000 2500 5000 FOENO;
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

hydra.RegionPrms-names              = clientRegion1	    clientRegion2		clientRegion3	bridgeRegion1     bridgeRegion2     bridgeRegion3	;
hydra.RegionPrms-regionName         = testRegion1		testRegion2         testRegion3	   	testRegion1		  testRegion2	    testRegion3		;
hydra.RegionPrms-scope              = local  			local				local         	default           default           default			;
hydra.RegionPrms-poolName           = edgeDescript      edgeDescript	    edgeDescript    none              none              none			;
hydra.RegionPrms-cacheListeners 	= util.SilenceListener;
hydra.RegionPrms-dataPolicy         = normal 			normal				normal          partition         partition         partition		;
hydra.RegionPrms-partitionName      = none              none                none    		pr1               pr2               pr3			;

hydra.PartitionPrms-names           = pr1	pr2	pr3;
hydra.PartitionPrms-localMaxMemory  = default;
hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-partitionResolver = parReg.colocation.MonthPartitionResolver;
hydra.PartitionPrms-colocatedWith = none testRegion1 testRegion2;
hydra.PartitionPrms-startupRecoveryDelay = -1;

parReg.ParRegPrms-partitionResolverData = BB;
parReg.ParRegPrms-isWithRoutingResolver = true; 

// define the edge clients
hydra.PoolPrms-names                       = edgeDescript;
hydra.PoolPrms-minConnections        	   = 20;
hydra.PoolPrms-subscriptionEnabled 		   = true;
hydra.PoolPrms-threadLocalConnections      = true;
hydra.PoolPrms-readTimeout                 = 3600000; // hydra will hang first
hydra.PoolPrms-subscriptionRedundancy      = 3;

// define the bridge servers
hydra.BridgePrms-names                = bridge;


parReg.ParRegPrms-numberOfDataStore = fcn "(${dataStorebridgeHosts} * ${dataStorebridgeVMsPerHost}) + (${rebalancebridgeHosts} * ${rebalancebridgeVMsPerHost})" ncf;

rebalance.RebalancePrms-resourceObserver = rebalance.RebalanceResourceObserver;
