hydra.Prms-testDescription = "
This test creates a number of (colocated) partitioned regions and loads the regions with data.  One dataStore VM is then recycled and recovery is verified to ensure that primaries are balanced.  
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2.inc;

STARTTASK    taskClass     = rebalance.ColocatedRecoveryTest taskMethod = StartTask_initialize;

INITTASK     taskClass     = rebalance.ColocatedRecoveryTest  taskMethod = HydraTask_HA_dataStoreInitialize
             hydra.ConfigPrms-cacheConfig = dataStore
             hydra.ConfigPrms-regionConfig = dataStore
             threadGroups = dataStoreVMThreads
             runMode = always;

INITTASK     taskClass     = rebalance.ColocatedRecoveryTest  taskMethod = HydraTask_HA_accessorInitialize
             hydra.ConfigPrms-cacheConfig = accessor
             hydra.ConfigPrms-regionConfig = accessor
             threadGroups = accessorVMThreads;

INITTASK     taskClass     = rebalance.ColocatedRecoveryTest  taskMethod = HydraTask_loadRegions
             threadGroups = accessorVMThreads
             batch;

INITTASK     taskClass   = rebalance.RebalanceUtil taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;

INITTASK     taskClass     = rebalance.RebalanceUtil taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

INITTASK     taskClass     = rebalance.RebalanceUtil taskMethod = primariesBalanced
             runMode = always
             threadGroups = dataStoreVMThreads;

TASK         taskClass     = rebalance.RecoveryStopStart taskMethod = HydraTask_stopStartDataStoreVm
             maxTimesToRun = 1
             threadGroups = controllerThread;

CLOSETASK    taskClass   = rebalance.RebalanceUtil taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;

CLOSETASK    taskClass   = rebalance.RebalanceUtil taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = rebalance.RebalanceUtil taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = rebalance.RebalanceUtil taskMethod  = HydraTask_verifyBucketCopiesBatched
             threadGroups = verifyThreads
             batch;

hydra.Prms-totalTaskTimeSec = 600;
hydra.Prms-maxResultWaitSec = 600;
//hydra.Prms-clientShutdownHook = parReg.ParRegUtil dumpAllPartitionedRegions;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ${byteArraySize};
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

parReg.ParRegPrms-numVMsToStop = RANGE 1 ${numVMsToStop} EGNAR;
parReg.ParRegPrms-stopModes = ONEOF MEAN_EXIT MEAN_KILL NICE_EXIT NICE_KILL FOENO;
parReg.ParRegPrms-highAvailability = true;
parReg.ParRegPrms-resourceObserver = rebalance.RebalanceResourceObserver;

hydra.VmPrms-extraVMArgs   = fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xmx128m \", ${${A}Hosts}, true)"
                             ncf
                             ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms1200m -Xmx1200m \", ${${B}Hosts}, true)"
                             ncf;


// this test uses tasks from getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per accessor and datastore vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf;

// accessorThreads are all threads in the accessor VMs minus 1 thread for the controller
// thread, minus one thread per accessor VM for the verifyThreads
THREADGROUP accessorVMThreads 
            totalThreads = fcn (${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM}) - 1
                               - (${${A}Hosts} * ${${A}VMsPerHost}) ncf  
            totalVMs     = fcn ${${A}Hosts} * ${${A}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\", 
                                ${${A}Hosts} * ${${A}VMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM}) 
                               - (${${B}Hosts} * ${${B}VMsPerHost}) ncf  
            totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${B}\", 
                                ${${B}Hosts} * ${${B}VMsPerHost}, true)" ncf;

// one thread from an accessor VM (it's the only thread not mapped to a thread group at this point)
THREADGROUP controllerThread totalThreads = 1 totalVMs = 1;

// to avoid bug 34430, scope must be ack
// numRegions regions with the base of RegionPrms-regionName will be created
// e.g. partitionedRegion_1 ... partitionedRegion_<numRegions>
// colocatedWith is set dynamically during initialization
// these will be colocated as shown below:
// region_1: none region_2->region1 ... region_n->region_n-1
rebalance.RebalancePrms-numRegions = 5;
hydra.Prms-useFixedRandomInMaster= true;
hydra.CachePrms-names           = accessor             dataStore;
hydra.RegionPrms-names          = accessor             dataStore;
hydra.RegionPrms-regionName     = partitionedRegion;
hydra.RegionPrms-dataPolicy     = partition;
hydra.RegionPrms-partitionName  = accessor             dataStore;

hydra.PartitionPrms-names           = accessor         dataStore;
hydra.PartitionPrms-localMaxMemory  = 0                default;
hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-recoveryDelay = 0;
hydra.PartitionPrms-startupRecoveryDelay = 0;

rebalance.RebalancePrms-resourceObserver = rebalance.RebalanceResourceObserver;
