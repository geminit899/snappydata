hydra.Prms-testDescription = "
This test creates a partitioned region, then does various entry operations on a 
known key range, while VMs are going up and down in a configuration that should 
result in no data loss. Values are checked for correctness in the close task.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2.inc;

STARTTASK    taskClass     = parReg.KnownKeysTest  taskMethod = StartTask_initialize;

INITTASK     taskClass     = parReg.KnownKeysTest  taskMethod = HydraTask_HA_dataStoreInitialize
             threadGroups = dataStoreVMThreads
             runMode = always;

INITTASK     taskClass     = parReg.KnownKeysTest  taskMethod = HydraTask_HA_accessorInitialize
             threadGroups = accessorVMThreads;

INITTASK     taskClass     = parReg.KnownKeysTest  taskMethod = HydraTask_loadRegion
             threadGroups = accessorVMThreads
             batch;

INITTASK     taskClass     = parReg.KnownKeysTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

INITTASK     taskClass     = parReg.KnownKeysTest  taskMethod = HydraTask_verifyRegionSize
             threadGroups = verifyThreads
             batch;

INITTASK     taskClass     = rebalance.RebalanceUtil taskMethod = primariesBalanced
             runMode = always
             threadGroups = dataStoreVMThreads;

TASK         taskClass     = parReg.KnownKeysTest  taskMethod = HydraTask_doOps
             threadGroups =  accessorVMThreads;

TASK         taskClass     = rebalance.RecoveryStopStart taskMethod = HydraTask_stopStartDataStoreVm
             maxTimesToRun = 1
             threadGroups = controllerThread;

CLOSETASK    taskClass   = parReg.KnownKeysTest  taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;

CLOSETASK    taskClass     = parReg.KnownKeysTest  taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.KnownKeysTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.KnownKeysTest  taskMethod  = HydraTask_verifyBucketCopiesBatched
             threadGroups = verifyThreads
             batch;

CLOSETASK    taskClass     = parReg.KnownKeysTest  taskMethod  = HydraTask_verifyRegionContents
             threadGroups = verifyThreads
             batch;

hydra.Prms-totalTaskTimeSec = 600;
hydra.Prms-maxResultWaitSec = 600;
hydra.Prms-clientShutdownHook = parReg.ParRegUtil dumpAllPartitionedRegions;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ${byteArraySize};
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

parReg.ParRegPrms-numVMsToStop = RANGE 1 ${numVMsToStop} EGNAR;
parReg.ParRegPrms-stopModes = ONEOF MEAN_EXIT MEAN_KILL NICE_EXIT NICE_KILL FOENO;
parReg.ParRegPrms-highAvailability = true;
parReg.ParRegPrms-resourceObserver = rebalance.RebalanceResourceObserver;

hydra.VmPrms-extraVMArgs   = fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xmx128m \", ${${A}Hosts}, true)"
                             ncf
                             ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms1200m -Xmx1200m \", ${${B}Hosts}, true)"
                             ncf;


// this test uses tasks from getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per accessor and datastore vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf;

// accessorThreads are all threads in the accessor VMs minus 1 thread for the controller
// thread, minus one thread per accessor VM for the verifyThreads
THREADGROUP accessorVMThreads 
            totalThreads = fcn (${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM}) - 1
                               - (${${A}Hosts} * ${${A}VMsPerHost}) ncf  
            totalVMs     = fcn ${${A}Hosts} * ${${A}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\", 
                                ${${A}Hosts} * ${${A}VMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM}) 
                               - (${${B}Hosts} * ${${B}VMsPerHost}) ncf  
            totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${B}\", 
                                ${${B}Hosts} * ${${B}VMsPerHost}, true)" ncf;

// one thread from an accessor VM (it's the only thread not mapped to a thread group at this point)
THREADGROUP controllerThread totalThreads = 1 totalVMs = 1;

// to avoid bug 34430, scope must be ack
hydra.Prms-useFixedRandomInMaster= true;
hydra.RegionPrms-names          = accessorRegion       dataStoreRegion;
hydra.RegionPrms-regionName     = partitionedRegion    partitionedRegion;
hydra.RegionPrms-dataPolicy     = partition;
hydra.RegionPrms-partitionName  = accessorPR           dataStorePR;

hydra.PartitionPrms-names           = accessorPR           dataStorePR;
hydra.PartitionPrms-localMaxMemory  = 0                    default;
hydra.PartitionPrms-redundantCopies = ${redundantCopies}   ${redundantCopies};
hydra.PartitionPrms-recoveryDelay = 0;
hydra.PartitionPrms-startupRecoveryDelay = 0;

rebalance.RebalancePrms-resourceObserver = rebalance.RebalanceResourceObserver;
