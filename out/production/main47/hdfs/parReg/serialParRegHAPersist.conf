hydra.Prms-testRequirement = "Test persistent partitioned regions with a variety of operations with careful validation and serial execution";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2_locator.inc;
hydra.Prms-manageLocatorAgents = true; // turn on master-managed locators
hydra.Prms-alwaysDoEndTasks = true;

STARTTASK taskClass   = hdfs.HDFSUtil
          taskMethod  = configureHadoopTask
          clientNames = locator1
          ;

INITTASK taskClass    = hdfs.HDFSUtil
         taskMethod   = startCluster
         threadGroups = locator
         ;

INITTASK     taskClass   = util.StopStartVMs  taskMethod = StopStart_initTask
             runMode = once
             threadGroups = accessorThreads, dataStoreThreads;

INITTASK     taskClass   = util.PRObserver  taskMethod = initialize
             runMode = once
             threadGroups = dataStoreThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_initializeDataStore
             runMode = once
             threadGroups = dataStoreThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_initializeAccessor
             runMode = once
             threadGroups = accessorThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_reinitializeAccessor
             runMode = dynamic
             threadGroups = accessorThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_reinitializeDataStore
             //parReg.ParRegPrms-recoverFromDisk = true
             runMode = dynamic
             threadGroups = dataStoreThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_waitForMyStartupRecovery
             threadGroups = dataStoreThreads;

INITTASK    taskClass   = parReg.ParRegTest  taskMethod = HydraTask_writeDiskDirsToBB
            threadGroups = dataStoreThreads
            runMode = once;

TASK         taskClass   = parReg.ParRegTest  taskMethod = HydraTask_doRROpsAndVerify
             threadGroups = dataStoreThreads, accessorThreads;

CLOSETASK   taskClass   = parReg.ParRegTest  taskMethod = HydraTask_prepareForValidation
             threadGroups = dataStoreThreads, accessorThreads;

CLOSETASK    taskClass   = parReg.ParRegUtil  taskMethod = HydraTask_rebalance
             threadGroups = dataStoreThreads;

CLOSETASK   taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validatePR
             threadGroups = dataStoreThreads, accessorThreads;

// recover from disk
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_initializeDataStore
            parReg.ParRegPrms-recoverFromDisk = true
            clientNames = fcn "hydra.TestConfigFcns.generateNames (\"dataStore\", ${dataStoreHosts}, true)" ncf;
//start accessors after recovering from disk.            
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_initializeAccessor
            clientNames = fcn "hydra.TestConfigFcns.generateNames (\"accessor\", ${accessorHosts}, true)" ncf;

// validate region contents while redundancy recovery is running,
// wait for redundancy recovery and verify PR internals 
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateRegionContents
            clientNames = dataStore1;
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_waitForMyStartupRecovery
            clientNames = fcn "hydra.TestConfigFcns.generateNames(\"dataStore\", ${dataStoreHosts}, true)" ncf;
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateInternalPRState
            clientNames = fcn "hydra.TestConfigFcns.generateNames (\"dataStore\", ${dataStoreHosts}, true)" ncf,
                          fcn "hydra.TestConfigFcns.generateNames (\"accessor\", ${accessorHosts}, true)" ncf;

// offline validation and compaction
//ENDTASK     taskClass   = parReg.ParRegTest     taskMethod = HydraTask_disconnect;
//ENDTASK     taskClass   = util.PersistenceUtil  taskMethod = HydraTask_doOfflineValAndCompactionOnce;

// recover from disk
//ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_prepareForRecovery;
//ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_initializeDataStore
            //parReg.ParRegPrms-recoverFromDisk = true
            //clientNames = fcn "hydra.TestConfigFcns.generateNames (\"dataStore\", ${dataStoreHosts}, true)" ncf;
//start accessors after recovering from disk.            
//ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_HA_initializeAccessor
            //clientNames = fcn "hydra.TestConfigFcns.generateNames (\"accessor\", ${accessorHosts}, true)" ncf;

// validate after compaction; validate region contents while redundancy recovery is running,
// wait for redundancy recovery and verify PR internals 
//ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateRegionContents;
//ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_waitForMyStartupRecovery
            //clientNames = fcn "hydra.TestConfigFcns.generateNames(\"dataStore\", ${dataStoreHosts}, true)" ncf;
//ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateInternalPRState;

ENDTASK taskClass   = hdfs.HDFSUtil
        taskMethod  = stopCluster
        clientNames = locator1
        ;

THREADGROUP locator
  totalThreads = fcn  ${locatorHosts} * ${locatorVMsPerHost} * ${locatorThreadsPerVM} ncf
  totalVMs     = fcn "(${locatorHosts} * ${locatorVMsPerHost})" ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"locator\", ${locatorHosts}, true)" ncf;

// all threads in subgroup A are accessorThreads, and all threads in subgroup B
// are in dataStoreThreads
THREADGROUP accessorThreads
    totalThreads = fcn
                   ${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"${A}\", ${${A}Hosts}, true)"
                   ncf;
THREADGROUP dataStoreThreads
    totalThreads = fcn
                   ${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"${B}\", ${${B}Hosts}, true)"
                   ncf;

hydra.GemFirePrms-stopSystemsAfterTest = true;

hydra.Prms-checkTaskMethodsExist = false;
hydra.Prms-doStartAndEndTasksLockStep = true;
hydra.Prms-maxEndTaskResultWaitSec = 7200;
hydra.Prms-totalTaskTimeSec = 1800;
hydra.Prms-maxResultWaitSec = 600;
hydra.Prms-serialExecution = true;
hydra.Prms-roundRobin = true;
hydra.Prms-clientShutdownHook = parReg.ParRegUtil dumpAllPartitionedRegions;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = 1000;
util.ValueHolderPrms-useExtraObject = true;
hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

parReg.ParRegPrms-numOpsPerTask = 100;

parReg.ParRegPrms-numPutAllNewKeys = useThreshold;
parReg.ParRegPrms-numPutAllExistingKeys = RANGE 0 50 EGNAR;

// todo@lhughes -- add destroys in (when validation updated to handle this)
parReg.ParRegPrms-entryOperations = ONEOF add putIfAbsentAsCreate getNew getNew update get putAll
                                          destroy remove
                                          replaceNoInval replaceOldNoInval 
                                    FOENO;
parReg.ParRegPrms-upperThreshold = 500;
parReg.ParRegPrms-upperThresholdOperations = ONEOF destroy remove FOENO;
parReg.ParRegPrms-lowerThreshold = 0;
parReg.ParRegPrms-lowerThresholdOperations = ONEOF add getNew putIfAbsentAsCreate putAll FOENO;
parReg.ParRegPrms-highAvailability = true;

parReg.ParRegPrms-numVMsToStop = ${numVMsToStop};
parReg.ParRegPrms-localMaxMemory = RANGE 1 10 EGNAR;
util.StopStartPrms-stopModes = ONEOF NICE_EXIT MEAN_KILL MEAN_EXIT NICE_KILL FOENO;
util.CachePrms-useDeclarativeXmlFile = false;

hydra.ConfigPrms-hadoopConfig = hadoop;
hydra.ConfigPrms-hdfsStoreConfig = hdfsstore;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

hydra.Prms-useFixedRandomInMaster= true;
hydra.RegionPrms-names          = clientRegion           dataStoreRegion;
hydra.RegionPrms-regionName     = partitionedRegion;
hydra.RegionPrms-dataPolicy     = hdfsPartition;
hydra.RegionPrms-hdfsStoreName  = hdfsstore;
hydra.RegionPrms-hdfsWriteOnly  = false;
hydra.RegionPrms-cacheLoader    = parReg.ParRegLoader;
hydra.RegionPrms-cacheListeners = util.SummaryLogListener;
hydra.RegionPrms-partitionName  = accessorPR               dataStorePR;

hydra.PartitionPrms-names           = accessorPR           dataStorePR;
hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-localMaxMemory  = 0                    default;

hydra.VmPrms-extraClassPaths +=
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${locatorHosts})" ncf
  ,
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${accessorHosts})" ncf
  ,
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${dataStoreHosts})" ncf
  ;


hydra.HadoopPrms-names = hadoop;

hydra.HDFSStorePrms-names = hdfsstore;
hydra.HDFSStorePrms-hadoopName = hadoop;
hydra.HDFSStorePrms-diskStoreName = disk;
hydra.HDFSStorePrms-batchSizeMB = 5;
hydra.HDFSStorePrms-homeDir = gemfire_data;
hydra.HDFSStorePrms-maximumQueueMemory = 100;
hydra.HDFSStorePrms-persistent = true;

hydra.DiskStorePrms-names = disk;
hydra.DiskStorePrms-queueSize = ONEOF 1 5 10 20 FOENO;
hydra.DiskStorePrms-timeInterval = oneof 1 10 50 500 1000 2000 foeno;

// not used in this test
//hydra.HDFSStorePrms-batchTimeInterval = ????;
//hydra.HDFSStorePrms-blockCacheSize = ????;
//hydra.HDFSStorePrms-diskSynchronous = true/false;
//hydra.HDFSStorePrms-fileRolloverInterval = ????;
//hydra.HDFSStorePrms-maxFileSize = ????;
