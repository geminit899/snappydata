hydra.Prms-testRequirement = "Test persistent partitioned regions with a variety of operations with careful validation and concurrent execution";

STARTTASK    taskClass = hdfs.HDFSUtil taskMethod = configureHadoopTask
             clientNames = client1
             ;

STARTTASK    taskClass = hdfs.HDFSUtil taskMethod = startCluster
             clientNames = client1 
             ;

INCLUDE $JTESTS/parReg/concParReg.conf;

// add another 100MB for the HDFS AEQ (maxMemory in MB)
hydra.VmPrms-extraVMArgs  += fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms400m -Xmx400m \", ${peerHosts}, true)"
                             ncf;

// prepare for end task recovery
INITTASK    taskClass   = parReg.ParRegTest  taskMethod = HydraTask_writeDiskDirsToBB
            runMode = once;

// each thread is also an admin vm so it can potentially call online backup
INITTASK     taskClass     = util.AdminHelper  taskMethod = HydraTask_initializeAdminDS;

// recover HDFS AEQ from disk 
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_initialize
            parReg.ParRegPrms-recoverFromDisk = true;

// validate region contents while redundancy recovery is running,
// wait for redundancy recovery and verify PR internals 
ENDTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateRegionContents
            clientNames = client1
            ;

ENDTASK     taskClass = hdfs.HDFSUtil taskMethod = stopCluster
            clientNames = client1 
            ;

parReg.ParRegPrms-entryOperations = ONEOF add getNew putIfAbsentAsCreate update get destroy remove
                                          add getNew putIfAbsentAsCreate replaceNoInval replaceOldNoInval 
                                    FOENO; 
parReg.ParRegPrms-upperThresholdOperations = ONEOF destroy remove FOENO;
parReg.ParRegPrms-lowerThresholdOperations = ONEOF add getNew putIfAbsentAsCreate FOENO;

// End tasks for persistent peer tests; recover from disk and validate recovery 
hydra.Prms-checkTaskMethodsExist = false;
hydra.Prms-alwaysDoEndTasks = true;
hydra.Prms-doStartAndEndTasksLockStep = true;
hydra.Prms-maxEndTaskResultWaitSec = 7200;
parReg.ParRegPrms-secondsToRun = 300;
hydra.Prms-maxResultWaitSec = 3600;  // allow more time for HDFS versions (since region size not limited) 
                                     // also, if we detect data inconsistency our mapreduce debug job takes
                                     // a significant amount of time to run.

util.AdminHelperPrms-adminInDsVm=true;

hydra.VmPrms-extraClassPaths += fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${peerHosts})" ncf;

hydra.ConfigPrms-hadoopConfig = hadoop;
hydra.ConfigPrms-hdfsStoreConfig = hdfsstore;

// let hydra think this is a normal partitioned region (so it doesn't require diskStore for opLogs)
hydra.RegionPrms-dataPolicy     = partitioned;
hydra.RegionPrms-diskStoreName = none;
hydra.RegionPrms-cacheListeners = util.SummaryLogListener;

// for now, do not attempt to re-initialize regions based on generated cache.xml files
util.CachePrms-useDeclarativeXmlFile = false;

hydra.HadoopPrms-names = hadoop;

hydra.RegionPrms-dataPolicy     = hdfsPartition;
hydra.RegionPrms-hdfsStoreName  = hdfsstore;
hydra.RegionPrms-hdfsWriteOnly  = false;
hydra.RegionPrms-diskStoreName  = none;

hydra.HDFSStorePrms-names = hdfsstore;
hydra.HDFSStorePrms-hadoopName = hadoop;
hydra.HDFSStorePrms-diskStoreName = disk;
hydra.HDFSStorePrms-batchSizeMB = 5;
hydra.HDFSStorePrms-homeDir = gemfire_data;
hydra.HDFSStorePrms-maximumQueueMemory = 50;
hydra.HDFSStorePrms-persistent = true;

hydra.DiskStorePrms-names = disk;
hydra.DiskStorePrms-queueSize = ONEOF 1 5 10 20 FOENO;
hydra.DiskStorePrms-timeInterval = oneof 1 10 50 500 1000 2000 foeno;

// not used in this test
//hydra.HDFSStorePrms-batchTimeInterval = ????;
//hydra.HDFSStorePrms-blockCacheSize = ????;
//hydra.HDFSStorePrms-diskSynchronous = true/false;
//hydra.HDFSStorePrms-fileRolloverInterval = ????;
//hydra.HDFSStorePrms-maxFileSize = ????;
