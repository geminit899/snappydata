include $JTESTS/hydraconfig/hydraparams1.inc;
include $JTESTS/hydraconfig/performance.inc;
include $JTESTS/hydraconfig/topology_wan_p2p.inc;
include $JTESTS/smoketest/perf/statmon.inc;

hydra.Prms-testDescription = "Same as perf084, but with 2 VMs in each WAN site and DataPolicy.REPLICATE.  Entries are byte arrays of size ${dataSize}.";

hydra.CachePrms-names = pub sub;

hydra.RegionPrms-names          = pubPrimary  pubPeer  subPrimary   subPeer;
hydra.RegionPrms-cacheListeners = none,       none,    cacheperf.gemfire.LatencyListener, none;
hydra.RegionPrms-dataPolicy     = replicate;
hydra.RegionPrms-enableGateway  = true;
hydra.RegionPrms-scope          = dack;

hydra.GatewayHubPrms-names         = gatewayHub;

hydra.GatewayPrms-names = gateway;
hydra.GatewayPrms-batchSize = 1000;
hydra.GatewayPrms-batchTimeInterval = 50;   // override default of 1000 ms 
hydra.GatewayPrms-diskStoreName = disk;

hydra.DiskStorePrms-names = disk;

// give the feed hub 1024 MB for the gateway queue + 256 MB to work with, and
// each put cycle should only put what will fit in the gateway queue without
// overflowing, but allow for key and entry overhead by using three-quarters

cacheperf.CachePerfPrms-gatewayQueueEntries =
  fcn 1024*750000/(${dataSize}*${peerThreadsPerVM}) ncf;
hydra.GatewayPrms-maximumQueueMemory = 1024;
hydra.VmPrms-extraVMArgs += -Xms1280m -Xmx1280m, -Xms256m -Xmx256m;
hydra.VmPrms-extraVMArgsSUN = -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC;

INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openStatisticsTask
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = pub
          hydra.ConfigPrms-regionConfig = pubPrimary
          threadgroups = pubPrimary
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = pub
          hydra.ConfigPrms-regionConfig = pubPeer
          threadgroups = pubPeer
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = sub
          hydra.ConfigPrms-regionConfig = subPrimary
          threadgroups = subPrimary
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = openCacheTask
          hydra.ConfigPrms-cacheConfig = sub
          hydra.ConfigPrms-regionConfig = subPeer
          threadgroups = subPeer
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = createGatewayHubTask
          hydra.ConfigPrms-gatewayHubConfig = gatewayHub
          threadgroups = pubPrimary, subPrimary
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = addGatewaysTask
          hydra.ConfigPrms-gatewayConfig = gateway
          threadgroups = pubPrimary
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = startGatewayHubTask
          threadgroups = pubPrimary, subPrimary
          ;
INITTASK  taskClass = cacheperf.CachePerfClient taskMethod = createDataTask
          batch
          cacheperf.CachePerfPrms-keyAllocation = ownKeys
          cacheperf.CachePerfPrms-warmupTerminatorMethod = none
          cacheperf.CachePerfPrms-taskTerminatorMethod = terminateOnMaxKey
          cacheperf.CachePerfPrms-taskTerminatorFrequency = 1 iterations
          threadgroups = pubPrimary
          ;
TASK      taskClass = cacheperf.CachePerfClient taskMethod = putDataGatewayTask
          cacheperf.CachePerfPrms-keyAllocation = ownKey
          cacheperf.CachePerfPrms-isMainWorkload = true
          threadGroups = pubPrimary
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeCacheTask
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = closeStatisticsTask
          ;
CLOSETASK taskClass = cacheperf.CachePerfClient taskMethod = reportTrimIntervalsTask
          ;

THREADGROUP pubPrimary
  totalThreads = ${peerThreadsPerVM}
  totalVMs = 1
  clientNames = client_1_1;
THREADGROUP pubPeer
  totalThreads = ${peerThreadsPerVM}
  clientNames = fcn "hydra.TestConfigFcns.generateNames(
                        \"client_1_\", ${peerHostsPerSite})" ncf;
THREADGROUP subPrimary
  totalThreads = ${peerThreadsPerVM}
  totalVMs = 1
  clientNames = client_2_1;
THREADGROUP subPeer
  totalThreads = ${peerThreadsPerVM}
  clientNames = fcn "hydra.TestConfigFcns.generateNames(
                        \"client_2_\", ${peerHostsPerSite})" ncf;

cacheperf.CachePerfPrms-maxKeys         = ${peerThreadsPerVM};
cacheperf.CachePerfPrms-objectType      = objects.ArrayOfByte;
objects.ArrayOfBytePrms-encodeKey       = true;
objects.ArrayOfBytePrms-encodeTimestamp = true;
objects.ArrayOfBytePrms-size            = ${dataSize};

cacheperf.CachePerfPrms-batchTerminatorMethod     = terminateOnBatchSeconds;
cacheperf.CachePerfPrms-batchSeconds              = 360;
cacheperf.CachePerfPrms-warmupTerminatorMethod    = terminateOnTrimSeconds;
cacheperf.CachePerfPrms-warmupTerminatorFrequency = 10 seconds;
cacheperf.CachePerfPrms-trimSeconds               = ${trimSeconds};
cacheperf.CachePerfPrms-taskTerminatorMethod      = terminateOnTotalSeconds;
cacheperf.CachePerfPrms-taskTerminatorFrequency   = 10 seconds;
cacheperf.CachePerfPrms-workSeconds               = 180;

hydra.Prms-totalTaskTimeSec = 259200;  // this test is workload based
hydra.Prms-maxResultWaitSec = 600;

perffmwk.PerfReportPrms-statisticsSpecification = $JTESTS/smoketest/perf/perf038.spec;
