hydra.Prms-testDescription = "
This test is for testing co-located PRs with random operation on the known set of keys.
This is a client-server test.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_hct.inc;

// This bridge flavor of concKnownKeysHA is a little different than
// the non-bridge flavor. In the non-bridge flavor, accessor VMs 
// (which correlate to edge clients) have a "handle" to the PR, and
// even though we don't store any data in the accessor, logically
// all the keys exist. In the bridge flavor, the edge clients, which
// have local regions, need to also have the keys in order for the ops
// task to do its work. For this reason, the edge clients must also
// keep all keys and values in it's locally scoped region, thus its
// vm must be as large as the data store (ie server) vms.


// this test uses tasks from getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per datastore (but not accessor) vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf
            totalVMs     = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"bridge\", 
                                ${bridgeHosts} * ${bridgeVMsPerHost}, true)" ncf;

// accessorThreads are all threads in the accessor VMs minus 1 thread for the controller
// thread
THREADGROUP accessorVMThreads 
            totalThreads = fcn "(${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM})" ncf
            totalVMs     = fcn "(${edgeHosts} * ${edgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"edge\", 
                                ${edgeHosts} * ${edgeVMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${bridgeHosts} * ${bridgeVMsPerHost} * ${bridgeThreadsPerVM}) 
                               - (${bridgeHosts} * ${bridgeVMsPerHost}) ncf  
            totalVMs     = fcn ${bridgeHosts} * ${bridgeVMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"bridge\", 
                                ${bridgeHosts} * ${bridgeVMsPerHost}, true)" ncf;


hydra.RegionPrms-names              = clientRegion1	    clientRegion2		clientRegion3           bridgeRegion1     bridgeRegion2     bridgeRegion3;
hydra.RegionPrms-regionName         = testRegion1		testRegion2         testRegion3	   			testRegion1		  testRegion2	    testRegion3;
hydra.RegionPrms-scope              = local  			local				local                	default           default           default;
hydra.RegionPrms-poolName           = edgeDescript      edgeDescript	    edgeDescript     		none              none              none;
hydra.RegionPrms-cacheListeners 	= util.SilenceListener,	util.SilenceListener	,util.SilenceListener	,	none,	none	,none;
hydra.RegionPrms-dataPolicy         = normal 			normal				normal                	partition         partition         partition;
hydra.RegionPrms-partitionName      = none              none                none    				pr1               pr2               pr3;

hydra.PartitionPrms-names           = pr1	pr2	pr3;
hydra.PartitionPrms-localMaxMemory  = default;
hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-partitionResolver = parReg.colocation.MonthPartitionResolver;
hydra.PartitionPrms-colocatedWith = none testRegion1 testRegion2;

parReg.ParRegPrms-partitionResolverData = BB;
parReg.ParRegPrms-isWithRoutingResolver = true; 

// define the edge clients
hydra.PoolPrms-names                       = edgeDescript;
hydra.PoolPrms-minConnections        	   = 2;
hydra.PoolPrms-subscriptionEnabled 		   = true;
hydra.PoolPrms-threadLocalConnections      = true;
hydra.PoolPrms-readTimeout                 = 3600000; // hydra will hang first
hydra.PoolPrms-subscriptionRedundancy        = ${redundancy};

// define the bridge servers
hydra.BridgePrms-names                = bridge;


parReg.ParRegPrms-numberOfDataStore = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf;

STARTTASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod = StartTask_initialize;

INITTASK     taskClass     = parReg.colocation.ParRegColocation  taskMethod = HydraTask_HA_dataStoreInitialize
             threadGroups = dataStoreVMThreads
             runMode = always;

INITTASK     taskClass     = parReg.colocation.ParRegColocation  taskMethod = HydraTask_HA_accessorInitialize
             threadGroups = accessorVMThreads;
             
INITTASK     taskClass     = parReg.colocation.ParRegColocation  taskMethod = HydraTask_registerInterest
             threadGroups = accessorVMThreads;

INITTASK     taskClass     = parReg.colocation.ParRegColocation  taskMethod = HydraTask_loadRegions
             threadGroups = accessorVMThreads
             batch
             ;

INITTASK     taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

INITTASK     taskClass     = parReg.colocation.ParRegColocation  taskMethod = HydraTask_verifyRegionSize
             threadGroups = verifyThreads
             ;
 
TASK         taskClass     = parReg.colocation.ParRegColocation  taskMethod = HydraTask_doOps
             threadGroups = accessorVMThreads;
 

CLOSETASK    taskClass   = parReg.colocation.ParRegColocation  taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;

CLOSETASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_verifyBucketCopies
             threadGroups = verifyThreads
             ;

CLOSETASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_verifyColocatedRegions
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_verifyRegionContents
             threadGroups = verifyThreads
             ;
             
           

hydra.Prms-totalTaskTimeSec = 14400; // test is workload based
hydra.Prms-maxResultWaitSec = 600;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ${byteArraySize};
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

parReg.ParRegPrms-numVMsToStop = RANGE 1 ${numVMsToStop} EGNAR;
parReg.ParRegPrms-stopModes = ONEOF MEAN_EXIT MEAN_KILL NICE_EXIT NICE_KILL FOENO;
parReg.ParRegPrms-highAvailability = true;

util.CachePrms-useDeclarativeXmlFile = true;
