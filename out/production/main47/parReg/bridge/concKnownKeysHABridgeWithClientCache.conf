hydra.Prms-testDescription = "
This test creates a partitioned region in bridge servers, then does various entry 
operations on a known key range, while servers are going up and down in a 
configuration that should result in no data loss. Values are checked for 
correctness in the close task.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_hct.inc;
INCLUDE $JTESTS/parReg/concKnownKeysHA.inc;

// This bridge flavor of concKnownKeysHA is a little different than
// the non-bridge flavor. In the non-bridge flavor, accessor VMs 
// (which correlate to edge clients) have a "handle" to the PR, and
// even though we don't store any data in the accessor, logically
// all the keys exist. In the bridge flavor, the edge clients, which
// have local regions, need to also have the keys in order for the ops
// task to do its work. For this reason, the edge clients must also
// keep all keys and values in it's locally scoped region, thus its
// vm must be as large as the data store (ie server) vms.
hydra.VmPrms-extraVMArgs   = fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms${serverVmSize}m -Xmx${serverVmSize}m \", ${bridgeHosts}, true)"
                             ncf
                             ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms${edgeVmSize}m -Xmx${edgeVmSize}m \", ${edgeHosts}, true)"
                             ncf;

// this test uses tasks from getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per datastore (but not accessor) vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf
            totalVMs     = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"bridge\", 
                                ${bridgeHosts} * ${bridgeVMsPerHost}, true)" ncf;

// accessorThreads are all threads in the accessor VMs minus 1 thread for the controller
// thread
THREADGROUP accessorVMThreads 
            totalThreads = fcn "(${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM}) - 1" ncf
            totalVMs     = fcn "(${edgeHosts} * ${edgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"edge\", 
                                ${edgeHosts} * ${edgeVMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${bridgeHosts} * ${bridgeVMsPerHost} * ${bridgeThreadsPerVM}) 
                               - (${bridgeHosts} * ${bridgeVMsPerHost}) ncf  
            totalVMs     = fcn ${bridgeHosts} * ${bridgeVMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"bridge\", 
                                ${bridgeHosts} * ${bridgeVMsPerHost}, true)" ncf;

// one thread from an accessor VM (it's the only thread not mapped to a thread group at this point)
THREADGROUP controllerThread totalThreads = 1 totalVMs = 1;

CLOSETASK     taskClass   = connPool.ConnPoolUtil  taskMethod = HydraTask_prepareForValidation
              connPool.ConnPoolPrms-sleepSec = 60
              threadGroups = dataStoreVMThreads;
CLOSETASK     taskClass   = connPool.ConnPoolUtil  taskMethod = HydraTask_validate
              threadGroups = dataStoreVMThreads;

// define the edge clients
hydra.ClientCachePrms-names     = clientCache;
hydra.ClientCachePrms-defaultPoolName  = defaultPool;

hydra.ClientRegionPrms-names      = accessorRegion;
hydra.ClientRegionPrms-regionName = testRegion;
hydra.ClientRegionPrms-clientRegionShortcut = CACHING_PROXY;

hydra.PoolPrms-names                    = defaultPool;
hydra.PoolPrms-minConnections           = 2;
hydra.PoolPrms-subscriptionEnabled      = true;
hydra.PoolPrms-threadLocalConnections   = false;
hydra.PoolPrms-readTimeout              = 3600000; // hydra will hang first
hydra.PoolPrms-subscriptionRedundancy   = ${redundantCopies};
hydra.PoolPrms-pingInterval             = 400;
hydra.PoolPrms-loadConditioningInterval = 5000;

// define the bridge servers
hydra.BridgePrms-names              = bridge;

hydra.RegionPrms-names              = dataStoreRegion;
hydra.RegionPrms-regionName         = testRegion;
hydra.RegionPrms-scope              = default;
hydra.RegionPrms-partitionName      = dataStorePR;
hydra.RegionPrms-dataPolicy         = partition;
hydra.RegionPrms-partitionName      = pr;

hydra.PartitionPrms-names           = pr;
hydra.PartitionPrms-localMaxMemory  = default;
hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-totalNumBuckets = 1000;
 
