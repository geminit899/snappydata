
hydra.Prms-testRequirement = "client VMs execute tx ops concurrently on bridgeServer which hosts colocated PRs along with other peers";
hydra.Prms-testDescription = "A single server VM shares colocated partitionedRegions with other peers in a DS.  Clients execute transactions on remote keys (in the server).";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_hct_2_locator.inc;

//------------------------------------------------------------------------------
// INITIALIZATION WORK 
//------------------------------------------------------------------------------

INITTASK  taskClass = parReg.tx.ColocatedTxTest taskMethod = createLocatorTask
          threadGroups = locator;

INITTASK  taskClass = parReg.tx.ColocatedTxTest taskMethod = startAndConnectLocatorTask
          threadGroups = locator;

INITTASK  taskClass   = parReg.tx.ColocatedTxTest taskMethod  = HydraTask_initializeBridgeServer
          hydra.ConfigPrms-bridgeConfig   = bridge
          hydra.ConfigPrms-cacheConfig    = bridge 
          hydra.ConfigPrms-regionConfig   = bridge
          threadGroups = bridge;

INITTASK  taskClass   = parReg.tx.ColocatedTxTest taskMethod  = HydraTask_initialize
          hydra.ConfigPrms-cacheConfig    = bridge
          hydra.ConfigPrms-regionConfig   = bridge
          threadGroups = PRthreads;

INITTASK  taskClass   = parReg.tx.ColocatedTxTest taskMethod  = HydraTask_initializeBridgeClient
          hydra.ConfigPrms-cacheConfig    = edge
          hydra.ConfigPrms-regionConfig   = edge
          threadGroups = edge;

INITTASK  taskClass   = parReg.tx.ColocatedTxTest taskMethod = HydraTask_populateRegions
          threadGroups = bridge;

TASK      taskClass = parReg.tx.ColocatedTxTest taskMethod = HydraTask_doEntryOperations
          threadGroups = edge;

THREADGROUP locator
    totalThreads = fcn ${locatorHosts} * ${locatorVMsPerHost}
                                       * ${locatorThreadsPerVM}
                   ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames
                        (\"locator\", ${locatorHosts}, true)"
                   ncf;
THREADGROUP bridge
  totalThreads = fcn
                 ${serverbridgeHosts} * ${serverbridgeVMsPerHost} * ${serverbridgeThreadsPerVM}
                 ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames
                      (\"serverbridge\", ${serverbridgeHosts}, true)"
                 ncf;
THREADGROUP PRthreads
  totalThreads = fcn
                 ${peerbridgeHosts} * ${peerbridgeVMsPerHost} * ${peerbridgeThreadsPerVM}
                 ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames
                      (\"peerbridge\", ${peerbridgeHosts}, true)"
                 ncf;
THREADGROUP edge
  totalThreads = fcn
                 ${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM}
                 ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames
                      (\"edge\", ${edgeHosts}, true)"
                 ncf;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = 500;
util.ValueHolderPrms-useExtraObject = true;

// todo@lhughes -- we will have to make add, putIfAbsent and putAll(addNew) work differently, right now it depends on 
// the region being partitioned, so we can call PartitionRegionHelper.getPrimaryMemberForKey() -- so we might have to execute
// it in a function ... since we can't add, I don't want to destroy/remove either (or we run out of keys to work on)
//util.OperationsClientPrms-entryOperations = ONEOF putAll putAll add add update update update update get get invalidate destroy putIfAbsent putIfAbsent replace replace remove FOENO;
util.OperationsClientPrms-entryOperations = ONEOF update update update update get get invalidate replace replace FOENO;

util.OperationsClientPrms-useTransactions = true;
util.OperationsClientPrms-numOpsPerTask = RANGE 3 5 EGNAR;
parReg.ParRegPrms-numPutAllNewKeys = 1;
parReg.ParRegPrms-numPutAllExistingKeys = RANGE 1 100 EGNAR;

hydra.GemFirePrms-conserveSockets = true;
hydra.GemFirePrms-stopSystemsAfterTest = true;
hydra.Prms-alwaysDoEndTasks = true;
hydra.Prms-clientShutdownHook = parReg.ParRegUtil dumpAllPartitionedRegions;

hydra.Prms-totalTaskTimeSec = 300;
hydra.Prms-maxResultWaitSec = 180;
hydra.Prms-haltIfBadResult = true;
hydra.Prms-serialExecution = false;
hydra.Prms-maxClientShutdownWaitSec = 360;
hydra.Prms-finalClientSleepSec = 60;
hydra.Prms-maxEndTaskResultWaitSec = 1800;

parReg.tx.PrTxPrms-numColocatedRegions = 5;
parReg.tx.PrTxPrms-useLocalKeySet = false;
parReg.tx.PrTxPrms-sameKeyColocatedRegions = ${sameKeyColocatedRegions};

hydra.CachePrms-names               = edge          bridge;

hydra.RegionPrms-names              = edge          bridge;
hydra.RegionPrms-regionName         = testRegion    testRegion;
hydra.RegionPrms-scope              = local         default;
hydra.RegionPrms-partitionName      = none          dataStorePR;
hydra.RegionPrms-poolName           = edgeDescript  none;
hydra.RegionPrms-dataPolicy         = normal        partition;
hydra.RegionPrms-partitionName      = none          pr;

hydra.PartitionPrms-names           = pr;
hydra.PartitionPrms-localMaxMemory  = default;
hydra.PartitionPrms-redundantCopies = 0;

// define the bridge servers
hydra.BridgePrms-names                = bridge;

// define the edge clients
hydra.PoolPrms-names                  = edgeDescript;
hydra.PoolPrms-minConnections         = 2;
hydra.PoolPrms-subscriptionEnabled    = true;
hydra.PoolPrms-threadLocalConnections = false;
hydra.PoolPrms-readTimeout            = 3600000; // hydra will hang first
hydra.PoolPrms-subscriptionRedundancy = 0;
hydra.PoolPrms-pingInterval           = 400;
hydra.PoolPrms-loadConditioningInterval = 5000;


