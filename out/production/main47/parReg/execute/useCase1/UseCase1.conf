hydra.Prms-testDescription = "
This test is for testing p2p use case for UseCase1 (this test also checks co-location of subRegion PR)
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2.inc;

hydra.VmPrms-extraVMArgs   = fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xmx128m \", ${${A}Hosts}, true)"
                             ncf
                             ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms1200m -Xmx1200m \", ${${B}Hosts}, true)"
                             ncf;


// this test uses tasks from getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per accessor and datastore vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf;

// accessorThreads are all threads in the accessor VMs 
THREADGROUP accessorVMThreads 
            totalThreads = fcn (${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM})
                               - (${${A}Hosts} * ${${A}VMsPerHost}) ncf  
            totalVMs     = fcn ${${A}Hosts} * ${${A}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\", 
                                ${${A}Hosts} * ${${A}VMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM}) 
                               - (${${B}Hosts} * ${${B}VMsPerHost}) ncf  
            totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${B}\", 
                                ${${B}Hosts} * ${${B}VMsPerHost}, true)" ncf;


hydra.RegionPrms-names              = rootRegion fxRateRegion	 	hierarchyRegion		industrySectorRegion   instrumentRegion					positionRegion  	 			sensitivityRegion 		undSensitivityRegion	positionRiskRegion   positionUndRiskRegion		accessorInstrumentRegion			accessorPositionRegion  			accessorSensitivityRegion	accessorUndSensitivityRegion	accessorPositionRiskRegion  accessorPositionUndRiskRegion;
hydra.RegionPrms-regionName         = rootRegion fxRateRegion		hierarchyRegion     industrySectorRegion   instrumentRegion  				positionRegion		 			sensitivityRegion 		undSensitivityRegion    positionRiskRegion   positionUndRiskRegion 		instrumentRegion					positionRegion  					sensitivityRegion			undSensitivityRegion  			positionRiskRegion			positionUndRiskRegion;
hydra.RegionPrms-cacheListeners 	= none       none,				none,				none,				   none,							parReg.execute.useCase1.RiskCalcListener,  none,			 		none,					none,				 none,						none,								parReg.execute.useCase1.RiskCalcListener,	none,						none,							none,						none;
hydra.RegionPrms-dataPolicy         = replicate  replicate 		replicate			replicate              partition       					partition          	 			partition		 		partition			    partition			 partition					partition       					partition          					partition					partition						partition					partition;
hydra.RegionPrms-partitionName      = none       none              none                none    			   pr1             					pr2                	 			pr3				 		pr4    			        pr5					 pr6                    	apr1                				apr2								apr3						apr4							apr5						apr6;

hydra.PartitionPrms-names           = pr1	    pr2 	pr3		pr4		pr5	 	pr6     apr1	apr2	apr3	apr4	apr5	apr6;
hydra.PartitionPrms-localMaxMemory  = default	default	default	default	default default 0		0		0		0		0		0;
hydra.PartitionPrms-redundantCopies = 1;
										  
hydra.PartitionPrms-colocatedWith = none	instrumentRegion	instrumentRegion	instrumentRegion 	none	none	none	instrumentRegion	instrumentRegion	instrumentRegion 	none	none;

parReg.ParRegPrms-numberOfDataStore = fcn "(${${B}Hosts} * ${${B}VMsPerHost})" ncf;


INITTASK     taskClass     = parReg.execute.useCase1.UseCase1UseCase  taskMethod = HydraTask_p2p_dataStoreInitialize
             threadGroups = dataStoreVMThreads
             runMode = always;

INITTASK     taskClass     = parReg.execute.useCase1.UseCase1UseCase  taskMethod = HydraTask_p2p_accessorInitialize
             threadGroups = accessorVMThreads 
             runMode = always;
             
                       
INITTASK     taskClass     = parReg.execute.useCase1.UseCase1UseCase  taskMethod = HydraTask_populateRegions
             threadGroups = accessorVMThreads 
             ;
             
TASK     taskClass     = parReg.execute.useCase1.UseCase1UseCase  taskMethod = HydraTask_logRegionSize
             threadGroups = verifyThreads
             maxTimesToRun = 1
             maxThreads = 1 
             ;             

CLOSETASK     taskClass     = parReg.execute.useCase1.UseCase1UseCase  taskMethod = HydraTask_verifyColocatedRegions
             threadGroups = verifyThreads 
             ;
                            
             
CLOSETASK     taskClass     = parReg.execute.useCase1.UseCase1UseCase  taskMethod = HydraTask_invalidateEntries
             threadGroups = verifyThreads 
             ;                        

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

hydra.Prms-maxResultWaitSec = 300;

