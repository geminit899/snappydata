hydra.Prms-testRequirement = "Test overflow to disk with resource manager set for heap eviction. 
Clients are kept light by evicting with destroy so they don't attempt to contain the whole PR.
Use lots of keys to stress things ";
hydra.Prms-testDescription = "
Create servers hosting a PR, configure resource manager for heap eviction
and overflow to disk. Clients created with destroy eviction to keep the clients light.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_4.inc;

hydra.GemFirePrms-distributedSystem =
                              fcn "hydra.TestConfigFcns.duplicate
                                   (\"bridgeds\", ${accessorHosts})"
                              ncf
                              fcn "hydra.TestConfigFcns.duplicate
                                   (\"bridgeds\", ${bridgeHosts})"
                              ncf
                              fcn "hydra.TestConfigFcns.duplicate
                                   (\"loner\", ${edgeHosts})"
                              ncf
                              fcn "hydra.TestConfigFcns.duplicate
                                   (\"bridgeds\", ${extraBridgeHosts})"
                              ncf;

// one verify thread per accessor, datastore and edge vm to verify each vm's view
THREADGROUP verifyThreads
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost}) +
                                (${${C}Hosts} * ${${C}VMsPerHost}) +
                                (${${D}Hosts} * ${${D}VMsPerHost})" ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost}) +
                                (${${C}Hosts} * ${${C}VMsPerHost}) +
                                (${${D}Hosts} * ${${D}VMsPerHost})" ncf;
THREADGROUP accessorThreads
  totalThreads = fcn
                 (${accessorHosts} * ${accessorVMsPerHost} * ${accessorThreadsPerVM}) - 
                 (${accessorHosts} * ${accessorVMsPerHost})
                 ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames
                      (\"accessor\", ${accessorHosts}, true)"
                 ncf;
THREADGROUP bridgeThreads
  totalThreads = fcn
                 (${bridgeHosts} * ${bridgeVMsPerHost} * ${bridgeThreadsPerVM}) - 
                 (${bridgeHosts} * ${bridgeVMsPerHost})
                 ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames
                      (\"bridge\", ${bridgeHosts}, true)"
                 ncf;
THREADGROUP edgeThreads
  totalThreads = fcn
                 (${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM}) - 
                 (${edgeHosts} * ${edgeVMsPerHost})
                 ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames
                      (\"edge\", ${edgeHosts}, true)"
                 ncf;         
THREADGROUP extraBridge1 totalThreads = 1 clientNames = extraBridge1;
THREADGROUP extraBridge2 totalThreads = 1 clientNames = extraBridge2;
THREADGROUP extraBridge3 totalThreads = 1 clientNames = extraBridge3;
THREADGROUP extraBridge4 totalThreads = 1 clientNames = extraBridge4;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_initializeBridgeServer
             threadGroups = bridgeThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_initializeBridgeServerAccessor
             threadGroups = accessorThreads;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_initialize
             threadGroups = edgeThreads;

// prepare for end task recovery
INITTASK    taskClass   = util.StopStartVMs  taskMethod = StopStart_initTask
            runMode = once;

INITTASK    taskClass   = parReg.ParRegTest  taskMethod = HydraTask_writeDiskDirsToBB
            threadGroups = bridgeThreads
            runMode = once;

INITTASK     taskClass   = parReg.ParRegTest  taskMethod = HydraTask_loadToUpperThreshold
             threadGroups = edgeThreads, bridgeThreads
             batch;

TASK         taskClass   = parReg.ParRegTest  taskMethod = HydraTask_doIntervalOps
             threadGroups = edgeThreads, bridgeThreads, accessorThreads;

// using the blackboard and StopSchedulingTaskOnClientOrder, the following rebalance tasks
// will have the effect of initializing the new vm and rebalancing one at a time
TASK         taskClass   = parReg.ParRegTest  taskMethod = HydraTask_startVmAndRebalance
             threadGroups = extraBridge1;
TASK         taskClass   = parReg.ParRegTest  taskMethod = HydraTask_startVmAndRebalance
             threadGroups = extraBridge2;
TASK         taskClass   = parReg.ParRegTest  taskMethod = HydraTask_startVmAndRebalance
             threadGroups = extraBridge3;
TASK         taskClass   = parReg.ParRegTest  taskMethod = HydraTask_startVmAndRebalance
             threadGroups = extraBridge4;

CLOSETASK   taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateIntervalOps
            threadGroups = verifyThreads
            batch; 

CLOSETASK   taskClass   = parReg.ParRegUtil  taskMethod = HydraTask_rebalance
            threadGroups = bridgeThreads;
      
CLOSETASK   taskClass   = parReg.ParRegTest  taskMethod = HydraTask_validateIntervalOps
            threadGroups = verifyThreads
            batch; 

hydra.GemFirePrms-stopSystemsAfterTest = true;

hydra.Prms-totalTaskTimeSec = 86400;
hydra.Prms-maxResultWaitSec = 600;
hydra.Prms-serialExecution = false;
hydra.Prms-clientShutdownHook = parReg.ParRegUtil dumpAllPartitionedRegions;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = 10;
util.ValueHolderPrms-useExtraObject = false;
hydra.GemFirePrms-conserveSockets = true;

util.CachePrms-useDeclarativeXmlFile = ONEOF true false FOENO;

util.TestHelperPrms-minTaskGranularitySec = 45;

parReg.ParRegPrms-upperThreshold = ${numKeys};
parReg.ParRegPrms-lockOperations = true;
parReg.ParRegPrms-opPercentage = 30;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;
hydra.CachePrms-resourceManagerName = resman;

hydra.ResourceManagerPrms-names = resman;
hydra.ResourceManagerPrms-evictionHeapPercentage = 20;
hydra.ResourceManagerPrms-criticalHeapPercentage = 99;

hydra.RegionPrms-names              = clientRegion            dataStoreRegion       PrAccessor;
hydra.RegionPrms-regionName         = testRegion              testRegion            testRegion;
hydra.RegionPrms-scope              = local                   default               default;
hydra.RegionPrms-poolName           = edgeDescript            none                  none;
//hydra.RegionPrms-cacheListeners     = util.SummaryLogListener;
hydra.RegionPrms-dataPolicy         = default                 partition             partition;
hydra.RegionPrms-partitionName      = none                    prDS                  prAcc;
hydra.RegionPrms-evictionAttributes = lruEntryCount 1000 localDestroy, 
                                      lruHeapPercentage default overflowToDisk;
hydra.RegionPrms-diskStoreName      = none                    diskStore1            none;
hydra.RegionPrms-diskSynchronous    = ONEOF true false FOENO;

hydra.DiskStorePrms-names = diskStore1;
hydra.DiskStorePrms-queueSize = ONEOF 1 5 10 20 FOENO;
hydra.DiskStorePrms-timeInterval = oneof 1 10 50 500 1000 2000 foeno;


hydra.PartitionPrms-names             = prDS                      prAcc;
//hydra.PartitionPrms-redundantCopies = ${redundantCopies};
hydra.PartitionPrms-localMaxMemory    = default                   0;
hydra.PartitionPrms-totalNumBuckets   = 1000;

// define the edge clients
hydra.PoolPrms-names                  = edgeDescript;
hydra.PoolPrms-minConnections         = 2;
hydra.PoolPrms-subscriptionEnabled           = true;
hydra.PoolPrms-threadLocalConnections = false;
hydra.PoolPrms-readTimeout            = 3600000; // hydra will hang first
hydra.PoolPrms-loadConditioningInterval     = 5000;

// define the bridge servers
hydra.BridgePrms-names                = bridge;
