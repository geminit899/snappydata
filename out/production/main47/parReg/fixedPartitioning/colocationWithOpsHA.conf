hydra.Prms-testDescription = "This test is for testing Fixed Partitioning of Partitioned Regions with colocation in peer to peer configuration with HA (fail over).
This test create the FPRs programmatically and uses 3 colocated FPR and 1 colocated FPR as sub region. Child regions does not set Fixed Partition Attributes.
The test uses XML to re-create cache and regions during the reinitialization (HA) scenario.
Fixed partition resolver is set as partition attribute and the colocated FPRs use one of two different resolver classes.
The test uses accessors (which have localMaxMemory 0 and no Fixed Partition Attributes (FPA) set), also datastore with and without FPAs set.
FPAs have different partition num buckets for different partitions but there is maximum one primary partition per member.
The test uses region operations and operations using function execution with HA. Test also uses random onRegion function executions - with/without filter, args, result collector with HA.
The test verifies the number of primaries of buckets, data consistency across buckets, ops validations, primary & secondary Fixed Partitioning, partition-num-buckets and FPR colocation.
The test also verifies that the rebalancing operation does not affect Fixed partitioning.
The number of datastores that get recycled at a time is from 1 to redundantCopies mentioned.";


INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2.inc;                                          

hydra.VmPrms-extraVMArgs   = 
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xmx128m \", ${${A}Hosts}, true)"
                              ncf
                              ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms512m -Xmx512m \", ${${B}Hosts}, true)"
                             ncf;


// this test uses tasks similar to getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per accessor and datastore vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf;

// accessorThreads are all threads in the accessor VMs minus 1 thread for the controller
// thread, minus one thread per accessor VM for the verifyThreads
THREADGROUP accessorVMThreads 
            totalThreads = fcn (${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM}) - 1
                               - (${${A}Hosts} * ${${A}VMsPerHost}) ncf  
            totalVMs     = fcn ${${A}Hosts} * ${${A}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\", 
                                ${${A}Hosts} * ${${A}VMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM}) 
                               - (${${B}Hosts} * ${${B}VMsPerHost}) ncf  
            totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${B}\", 
                                ${${B}Hosts} * ${${B}VMsPerHost}, true)" ncf;
                                                               
// one thread from an accessor VM (it's the only thread not mapped to a thread group at this point)
THREADGROUP controllerThread totalThreads = 1 totalVMs = 1;                                                                

STARTTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = StartTask_initialize;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_p2p_dataStoreInitialize
             hydra.ConfigPrms-cacheConfig = cache
             threadGroups = dataStoreVMThreads
             runMode = always
             SEQUENTIAL;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_p2p_accessorInitialize
             hydra.ConfigPrms-cacheConfig = cache
             threadGroups = accessorVMThreads;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_loadRegionsWithFuncExec
             threadGroups = accessorVMThreads
             batch
             ;                         

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_verifyRegionSize
             threadGroups = verifyThreads
             ; 
             
INITTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_putKeySetInBB
             threadGroups = verifyThreads
			 ;       
			 
             
INITTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_updateBBWithPartitionInfo
             threadGroups = verifyThreads
			 ;	
 
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doOps
             threadGroups = accessorVMThreads; 
             
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doFunctionExecution_HA
             threadGroups = accessorVMThreads; 
             
//TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doRandomFuncExec
//             threadGroups = accessorVMThreads;   
             
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_stopStartVms
             threadGroups = controllerThread;                                               
                                
CLOSETASK    taskClass   = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;               

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyBucketCopies
             threadGroups = verifyThreads
             ;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyRegionContents
             threadGroups = verifyThreads
             ;
             
CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFixedPartitioning
             threadGroups = verifyThreads
             ;             
             
CLOSETASK    taskClass     = parReg.ParRegUtil  taskMethod  = HydraTask_rebalance
             threadGroups = verifyThreads
             ;                                                                
                          
CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFixedPartitioning
             threadGroups = verifyThreads
             ;
             
CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFPRCoLocation
             threadGroups = verifyThreads
             ;             
             
             

hydra.Prms-totalTaskTimeSec = 14400; // test is workload based
hydra.Prms-maxResultWaitSec = 1200;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ${byteArraySize};
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache;
hydra.CachePrms-searchTimeout   = 600;

hydra.RegionPrms-names          = dataStoreRegion1  dataStoreRegion2  dataStoreRegion3  accessorRegion1  accessorRegion2 accessorRegion3    rootRegion          aRootRegion      subRegion         aSubRegion;
hydra.RegionPrms-regionName     = testRegion1       testRegion2       testRegion3       testRegion1      testRegion2     testRegion3        rootRegion          rootRegion       subRegion         subRegion;
hydra.RegionPrms-cacheListeners = util.SilenceListener;
hydra.RegionPrms-scope          = default           default           default           default          default         default            distributedAck      distributedAck   default           default;
hydra.RegionPrms-dataPolicy     = partition         partition         partition         partition        partition       partition          replicate           replicate        partition         partition;
hydra.RegionPrms-partitionName  = prDS1             prDS2             prDS3             prAcc1           prAcc2          prAcc3             none                none             prDSSub           prAccSub;                                                              
                
hydra.PartitionPrms-names              = prDS1      prDS2       prDS3       prAcc1      prAcc2      prAcc3      prDSSub      prAccSub;
hydra.PartitionPrms-localMaxMemory     = default    default     default     0           0           0           default      0;
hydra.PartitionPrms-redundantCopies    = ${redundantCopies};
hydra.PartitionPrms-totalNumBuckets    = 8;
hydra.PartitionPrms-partitionResolver  = parReg.fixedPartitioning.NodePartitionResolver;
hydra.PartitionPrms-fixedPartitionName = quarters none;

hydra.PartitionPrms-colocatedWith      = none     testRegion1 testRegion2 none        testRegion1 testRegion2 testRegion1  testRegion1;
 
hydra.FixedPartitionPrms-names            = quarters;
hydra.FixedPartitionPrms-partitionNames   = Quarter1 Quarter2 Quarter3 Quarter4;
hydra.FixedPartitionPrms-partitionBuckets = 1         3        1        3;
hydra.FixedPartitionPrms-datastores       = fcn "(${${B}Hosts} * ${${B}VMsPerHost})" ncf;
           
parReg.ParRegPrms-partitionResolverData = BB;
parReg.ParRegPrms-isWithRoutingResolver = true;

hydra.VmPrms-extraClassPaths = $GEMFIRE/lib/antlr.jar; 

parReg.ParRegPrms-numVMsToStop = RANGE 1 ${numVMsToStop} EGNAR;
parReg.ParRegPrms-stopModes = ONEOF MEAN_EXIT MEAN_KILL NICE_EXIT NICE_KILL FOENO;
parReg.ParRegPrms-highAvailability = true; 
