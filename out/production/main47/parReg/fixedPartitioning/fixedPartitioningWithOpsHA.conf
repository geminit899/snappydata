hydra.Prms-testDescription = "This test is for testing Fixed Partitioning of Partitioned Region in peer to peer configuration with HA (fail over).
This test create the FPRs programmatically.
The test uses XML to re-create cache and region during the reinitialization (HA) scenario.
Fixed partition resolver is set as partition attribute.
The test uses accessors (which have localMaxMemory 0 and no Fixed Partition Attributes (FPA) set), also datastore with and without FPAs set.
FPAs have different partition num buckets for different partitions but there is maximum one primary partition per member.
The test uses region operations and operations using function execution with HA. Test also uses random onRegion function executions - with/without filter, args, result collector with HA.
The test verifies the number of primaries of buckets, data consistency across buckets, ops validations, primary & secondary Fixed Partitioning and partition-num-buckets.
The test also verifies that the rebalancing operation does not affect Fixed partitioning.
The number of datastores that get recycled at a time is from 1 to redundantCopies mentioned.";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_p2p_2.inc;                                          

hydra.VmPrms-extraVMArgs   = 
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xmx128m \", ${${A}Hosts}, true)"
                              ncf
                              ,
                             fcn "hydra.TestConfigFcns.duplicate
                                  (\"-Xms512m -Xmx512m \", ${${B}Hosts}, true)"
                             ncf;


// this test uses tasks similar to getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per accessor and datastore vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost}) +
                                (${${B}Hosts} * ${${B}VMsPerHost})" ncf;

// accessorThreads are all threads in the accessor VMs minus 1 thread for the controller
// thread, minus one thread per accessor VM for the verifyThreads
THREADGROUP accessorVMThreads 
            totalThreads = fcn (${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM}) - 1
                               - (${${A}Hosts} * ${${A}VMsPerHost}) ncf  
            totalVMs     = fcn ${${A}Hosts} * ${${A}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\", 
                                ${${A}Hosts} * ${${A}VMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM}) 
                               - (${${B}Hosts} * ${${B}VMsPerHost}) ncf  
            totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${B}\", 
                                ${${B}Hosts} * ${${B}VMsPerHost}, true)" ncf;
                                
// one thread from an accessor VM (it's the only thread not mapped to a thread group at this point)
THREADGROUP controllerThread totalThreads = 1 totalVMs = 1;     

STARTTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = StartTask_initialize;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_p2p_dataStoreInitialize
	     hydra.ConfigPrms-regionConfig = dataStoreRegion
	     hydra.ConfigPrms-cacheConfig = cache
             threadGroups = dataStoreVMThreads
             runMode = always
             SEQUENTIAL;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_p2p_accessorInitialize
	     hydra.ConfigPrms-regionConfig = accessorRegion
	     hydra.ConfigPrms-cacheConfig = cache
             threadGroups = accessorVMThreads;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_loadRegionsWithFuncExec
             threadGroups = accessorVMThreads
             batch
             ;            

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_verifyRegionSize
             threadGroups = verifyThreads
             ; 
             
INITTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFixedPartitioning
             threadGroups = verifyThreads
             ;             
             
INITTASK    taskClass     = parReg.colocation.ParRegColocation  taskMethod  = HydraTask_putKeySetInBB
             threadGroups = verifyThreads
			 ;    
			 
INITTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_updateBBWithPartitionInfo
             threadGroups = verifyThreads
			 ;			                      
 
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doOps
             threadGroups = accessorVMThreads; 
             
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doFunctionExecution_HA
             threadGroups = accessorVMThreads;  
             
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_stopStartVms
             threadGroups = controllerThread; 
                                                                               
CLOSETASK    taskClass   = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyBucketCopies
             threadGroups = verifyThreads
             ;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyRegionContents
             threadGroups = verifyThreads
             ;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFixedPartitioning
             threadGroups = verifyThreads
             ; 
             
CLOSETASK    taskClass     = parReg.ParRegUtil  taskMethod  = HydraTask_rebalance
             threadGroups = verifyThreads
             ;                                                                
                          
CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFixedPartitioning
             threadGroups = verifyThreads
             ;                                                   
                          

hydra.RegionPrms-names          = dataStoreRegion  accessorRegion;
hydra.RegionPrms-regionName     = testRegion       testRegion;
hydra.RegionPrms-cacheListeners = util.SilenceListener,  util.SilenceListener;
hydra.RegionPrms-scope          = default          default;
hydra.RegionPrms-dataPolicy     = partition        partition;
hydra.RegionPrms-partitionName  = prDS             prAcc;                                                               
                
hydra.PartitionPrms-names              = prDS               prAcc;
hydra.PartitionPrms-redundantCopies    = ${redundantCopies};
hydra.PartitionPrms-localMaxMemory     = default            0;
hydra.PartitionPrms-totalNumBuckets    = 113                113;
hydra.PartitionPrms-partitionResolver  = parReg.fixedPartitioning.NodePartitionResolver  parReg.fixedPartitioning.NodePartitionResolver;
hydra.PartitionPrms-fixedPartitionName = quarters           none;

hydra.FixedPartitionPrms-names            = quarters;
hydra.FixedPartitionPrms-partitionNames   = Quarter1 Quarter2 Quarter3 Quarter4;
hydra.FixedPartitionPrms-partitionBuckets = 1         3        1        3;
hydra.FixedPartitionPrms-datastores       = fcn "(${${B}Hosts} * ${${B}VMsPerHost})" ncf;

hydra.Prms-totalTaskTimeSec = 14400; // test is workload based
hydra.Prms-maxResultWaitSec = 900;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ${byteArraySize};
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache;
hydra.CachePrms-searchTimeout   = 600;
           
parReg.ParRegPrms-partitionResolverData = BB;
parReg.ParRegPrms-isWithRoutingResolver = true;

hydra.VmPrms-extraClassPaths = $GEMFIRE/lib/antlr.jar;

parReg.ParRegPrms-numVMsToStop = RANGE 1 ${numVMsToStop} EGNAR;
parReg.ParRegPrms-stopModes = ONEOF MEAN_EXIT MEAN_KILL NICE_EXIT NICE_KILL FOENO;
parReg.ParRegPrms-highAvailability = true; 
