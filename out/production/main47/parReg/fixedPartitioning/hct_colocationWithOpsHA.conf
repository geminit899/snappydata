hydra.Prms-testDescription = "This test is for testing Fixed Partitioning of Partitioned Regions with colocation in client server configuration with HA (fail over).
This test create the FPRs programmatically and uses 3 colocated FPR and 1 colocated FPR as sub region. Child regions does not set Fixed Partition Attributes.
The test uses XML to re-create cache and regions during the reinitialization (HA) scenario.
Fixed partition resolver is set as partition attribute and the colocated FPRs use one of two different resolver classes.
The test uses accessors (which have localMaxMemory 0 and no Fixed Partition Attributes (FPA) set), also datastore with and without FPAs set.
FPAs have different partition num buckets for different partitions but there is maximum one primary partition per member.
The test uses region operations and operations using function execution with HA. Test also uses random onRegion function executions - with/without filter, args, result collector with HA.
The test verifies the number of primaries of buckets, data consistency across buckets, ops validations, primary & secondary Fixed Partitioning, partition-num-buckets and FPR colocation.
The test also verifies that the rebalancing operation does not affect Fixed partitioning.
The number of datastores that get recycled at a time is from 1 to redundantCopies mentioned.";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_hct.inc;


// this test uses tasks similar to getInitialImage tests to load the region,
// do operations and verify the region contents 

// one verify thread per datastore (but not accessor) vm to verify each vm's view
THREADGROUP verifyThreads 
            totalThreads = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf
            totalVMs     = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"bridge\", 
                                ${bridgeHosts} * ${bridgeVMsPerHost}, true)" ncf;

// accessorThreads are all threads in the accessor VMs 
THREADGROUP accessorVMThreads 
            totalThreads = fcn "(${edgeHosts} * ${edgeVMsPerHost} * ${edgeThreadsPerVM}) - 1" ncf
            totalVMs     = fcn "(${edgeHosts} * ${edgeVMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"edge\", 
                                ${edgeHosts} * ${edgeVMsPerHost}, true)" ncf;

// dataStoreThreads are all threads in the dataStore VMs minus 
// the one thread per dataStore VM for the verifyThreads
THREADGROUP dataStoreVMThreads 
            totalThreads = fcn (${bridgeHosts} * ${bridgeVMsPerHost} * ${bridgeThreadsPerVM}) 
                               - (${bridgeHosts} * ${bridgeVMsPerHost}) ncf  
            totalVMs     = fcn ${bridgeHosts} * ${bridgeVMsPerHost} ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"bridge\", 
                                ${bridgeHosts} * ${bridgeVMsPerHost}, true)" ncf; 
                                
// one thread from an accessor VM (it's the only thread not mapped to a thread group at this point)
THREADGROUP controllerThread totalThreads = 1 totalVMs = 1;                             


parReg.ParRegPrms-partitionResolverData = BB;
parReg.ParRegPrms-isWithRoutingResolver = true; 

// define the edge clients
hydra.PoolPrms-names                       = edgeDescript;
hydra.PoolPrms-minConnections        	   = 2;
hydra.PoolPrms-subscriptionEnabled 		   = true;
hydra.PoolPrms-threadLocalConnections      = true;
hydra.PoolPrms-readTimeout                 = 3600000; // hydra will hang first
hydra.PoolPrms-subscriptionRedundancy        = ${redundancy};

// define the bridge servers
hydra.BridgePrms-names                = bridge;

STARTTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = StartTask_initialize;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_HA_dataStoreInitialize
             hydra.ConfigPrms-cacheConfig = cache
             threadGroups = dataStoreVMThreads
             runMode = always
             SEQUENTIAL;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_HA_accessorInitialize
             hydra.ConfigPrms-cacheConfig = cache             
             threadGroups = accessorVMThreads;
             
INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_registerInterest
             threadGroups = accessorVMThreads;
             
INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_initRegisterFunction
             threadGroups = verifyThreads, accessorVMThreads
             ;
             
INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_loadRegions
             threadGroups = accessorVMThreads
             batch
             ;
             
INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_putKeySetInBB
             threadGroups = verifyThreads
			 ;   
			 			           

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

INITTASK     taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_verifyRegionSize
             threadGroups = verifyThreads
             ;
             
INITTASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_updateBBWithPartitionInfo
             threadGroups = verifyThreads
			 ;             
 
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doOps
             threadGroups = accessorVMThreads;
             
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_doFunctionExecution_HA
             threadGroups = accessorVMThreads;      
             
TASK         taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_stopStartVms
             threadGroups = controllerThread;                   

CLOSETASK    taskClass   = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod = HydraTask_logLocalSize
             threadGroups = dataStoreVMThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPrimaries
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyPRMetaData
             threadGroups = verifyThreads;

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyBucketCopies
             threadGroups = verifyThreads
             ;
             
CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyFixedPartitioning
             threadGroups = verifyThreads
             ;             

CLOSETASK    taskClass     = parReg.fixedPartitioning.FixedPartitioningTest  taskMethod  = HydraTask_verifyRegionContents
             threadGroups = verifyThreads
             ;
             
CLOSETASK    taskClass     = parReg.fixedPartitioning.KeyCallbackResolverTest  taskMethod  = HydraTask_verifyFPRCoLocation
             threadGroups = verifyThreads
             ;                          
             
           
hydra.RegionPrms-names          = dataStoreRegion1  dataStoreRegion2  dataStoreRegion3  rootRegion      subRegion   accessorRegion1  accessorRegion2 accessorRegion3  aRootRegion  aSubRegion;
hydra.RegionPrms-regionName     = testRegion1       testRegion2       testRegion3       rootRegion      subRegion   testRegion1      testRegion2     testRegion3      rootRegion   subRegion;
hydra.RegionPrms-cacheListeners = util.SilenceListener;                                 
hydra.RegionPrms-scope          = default           default           default           distributedAck  default     local;
hydra.RegionPrms-dataPolicy     = partition         partition         partition         replicate       partition   normal;
hydra.RegionPrms-partitionName  = prDS1             prDS2             prDS3             none            prDSSub     none;                                                              

hydra.RegionPrms-poolName       = none              none              none              none            none        edgeDescript;

hydra.PartitionPrms-names              = prDS1      prDS2        prDS3       prDSSub;
hydra.PartitionPrms-redundantCopies    = ${redundantCopies};
hydra.PartitionPrms-localMaxMemory     = default    default      default     default;
hydra.PartitionPrms-totalNumBuckets    = 8;
hydra.PartitionPrms-partitionResolver  = parReg.fixedPartitioning.NodePartitionResolver;
hydra.PartitionPrms-fixedPartitionName = quarters   none;

hydra.PartitionPrms-colocatedWith      = none       testRegion1  testRegion2 testRegion1;

hydra.FixedPartitionPrms-names            = quarters;
hydra.FixedPartitionPrms-partitionNames   = Quarter1 Quarter2 Quarter3 Quarter4;
hydra.FixedPartitionPrms-partitionBuckets = 1         3        1        3;
hydra.FixedPartitionPrms-datastores       = fcn "(${bridgeHosts} * ${bridgeVMsPerHost})" ncf;

hydra.Prms-totalTaskTimeSec = 14400; // test is workload based
hydra.Prms-maxResultWaitSec = 900;

util.TestHelperPrms-minTaskGranularitySec = 60;

getInitialImage.InitImagePrms-numKeys = ${numKeys};
// numNewKeys is 10% of the total number of keys
getInitialImage.InitImagePrms-numNewKeys = fcn "${numKeys} * 0.1" ncf;
getInitialImage.InitImagePrms-useCacheLoader=false;

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = ${byteArraySize};
util.ValueHolderPrms-useExtraObject = true;

hydra.GemFirePrms-conserveSockets = ONEOF true false FOENO;

hydra.CachePrms-names           = cache;
hydra.CachePrms-searchTimeout   = 600;

util.CachePrms-useDeclarativeXmlFile = false;

hydra.VmPrms-extraClassPaths = $GEMFIRE/lib/antlr.jar; 

parReg.ParRegPrms-numVMsToStop = RANGE 1 ${numVMsToStop} EGNAR;
parReg.ParRegPrms-stopModes = ONEOF MEAN_EXIT MEAN_KILL NICE_EXIT NICE_KILL FOENO;
parReg.ParRegPrms-highAvailability = true;
