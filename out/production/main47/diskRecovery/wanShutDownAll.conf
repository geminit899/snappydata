hydra.Prms-testRequirement = "Test to verify fix for 43945. 43945 is about data consistency in a wan configuration while updates are running while shutDownAll is called on a wan site. Note that we do not support persistenct replicates (only persistent PRs) and we do not support updates running on the wan site that is shut down with shutDownAll. ";
hydra.Prms-testDescription = "Create 2 wan sites, load PRs (no replicates) with data, do updates on wan site 1 while wan site 2 does a shutDownAll and recovery from disk. Pause the updates,
wait for silence, somebody in wan site 1 writes to the blackboard and all jvms verify against it in both wan sites.
";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_wan_p2p_2_locator.inc;

THREADGROUP locatorThreads
  totalThreads = fcn ${wanSites} * ${locatorHostsPerSite}
                 * ${locatorVMsPerHost} * ${locatorThreadsPerVM} ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateDoubleSuffixedNames
              (\"locator\", ${wanSites}, ${locatorHostsPerSite}, false, true)"
                 ncf;
THREADGROUP adminThreadsSite1
  totalThreads = fcn ${${A}HostsPerSite}
                   * ${${A}VMsPerHost} * ${${A}ThreadsPerVM} ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateDoubleSuffixedFixedNames
              (\"${A}\", 1, ${${A}HostsPerSite}, true)"
                 ncf;
THREADGROUP adminThreadsSite2
  totalThreads = fcn ${${A}HostsPerSite}
                   * ${${A}VMsPerHost} * ${${A}ThreadsPerVM} ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateDoubleSuffixedFixedNames
              (\"${A}\", 2, ${${A}HostsPerSite}, true)"
                 ncf;
THREADGROUP peerThreadsSite1 
  totalThreads = fcn ${${B}HostsPerSite}
                   * ${${B}VMsPerHost} * ${${B}ThreadsPerVM} ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateDoubleSuffixedFixedNames
              (\"${B}\", 1, ${${B}HostsPerSite}, true)"
                 ncf;
THREADGROUP peerThreadsSite2
  totalThreads = fcn ${${B}HostsPerSite}
                   * ${${B}VMsPerHost} * ${${B}ThreadsPerVM} ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateDoubleSuffixedFixedNames
              (\"${B}\", 2, ${${B}HostsPerSite}, true)"
                 ncf;

// stop/start init
INITTASK taskClass   = util.StopStartVMs  taskMethod = StopStart_initTask
         threadGroups = peerThreadsSite2;

// locator init
INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = createLocatorTask
         threadGroups = locatorThreads;
INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = startAndConnectLocatorTask
         threadGroups = locatorThreads;

// init regions
INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_initialize
         runMode = always
         threadGroups = peerThreadsSite1, peerThreadsSite2;

INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_serversAreBack
         runMode = dynamic
         threadGroups = peerThreadsSite2;

// wan init
INITTASK     taskClass   = diskRecovery.StartupShutdownTest  taskMethod = HydraTask_createGatewayHub
             threadGroups = peerThreadsSite1, peerThreadsSite2
             runMode = always;
INITTASK     taskClass   = diskRecovery.StartupShutdownTest  taskMethod = HydraTask_addGatewayHub
             threadGroups = peerThreadsSite1, peerThreadsSite2
             runMode = always;
INITTASK     taskClass   = diskRecovery.StartupShutdownTest  taskMethod = HydraTask_startGatewayHub
             threadGroups = peerThreadsSite1, peerThreadsSite2
             runMode = always;

INITTASK taskClass = util.AdminHelper  taskMethod = HydraTask_initializeAdminDS
         threadGroups = adminThreadsSite1, adminThreadsSite2;

INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_load
         batch
         threadGroups = peerThreadsSite1;

// wait for all the wan events to arrive at their destination
INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_waitForSilence
         runMode = always
         threadGroups = peerThreadsSite1, peerThreadsSite2;

INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_verifyRegionSizes
         runMode = always
         threadGroups = peerThreadsSite1, peerThreadsSite2;

INITTASK taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_verifyFromLeaderSnapshot
         runMode = dynamic
         threadGroups = peerThreadsSite1, peerThreadsSite2;

TASK     taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_doWanUpdates
         threadGroups = peerThreadsSite1;

TASK     taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_wanShutDownAll
         maxTimesToRun=1
         threadGroups = adminThreadsSite2;

// for 6.5 we do not support data consistency while ops are running on the site doing shutDownAll
//TASK     taskClass = diskRecovery.StartupShutdownTest taskMethod = HydraTask_doWanUpdatesDuringShutDownAll
//         threadGroups = peerThreadsSite2;

RANDOMINCLUDE $JTESTS/memscale/configs/enableOffHeap.conf;
INCLUDE $JTESTS/memscale/configs/verifyOffHeap.conf;

hydra.GatewayHubPrms-names = gatewayHub;
hydra.GatewayHubPrms-haEnabled = true;

hydra.GatewayPrms-names = gateway;
hydra.GatewayPrms-enablePersistence = true;
hydra.GatewayPrms-maximumQueueMemory = 1;
hydra.GatewayPrms-diskStoreName = ONEOF diskStore1 diskStore2 FOENO;
hydra.GatewayPrms-batchConflation = ${batchConflation};

hydra.Prms-maxResultWaitSec = 1200;
hydra.Prms-totalTaskTimeSec = 3600; // test is workload based and shouldn't run this long

INCLUDE $JTESTS/util/randomValues.inc;
util.RandomValuesPrms-objectType = byte[];
util.RandomValuesPrms-elementSize = 1024;
util.ValueHolderPrms-useExtraObject = true;
hydra.GemFirePrms-conserveSockets = false ;

hydra.CachePrms-names           = cache1;
hydra.CachePrms-searchTimeout   = 600;

hydra.Prms-useFixedRandomInMaster= true;
hydra.RegionPrms-names           = persistReplicate       persistPR            clientRegion   proxyReplicate proxyPR;
hydra.RegionPrms-dataPolicy      = persistentReplicate    persistentPartition  normal         empty          partition;
hydra.RegionPrms-scope           = ack                    default              local          ack            default;
hydra.RegionPrms-diskStoreName   = diskStore1             diskStore2           none           none           none;
hydra.RegionPrms-diskSynchronous = true                   false;
hydra.RegionPrms-partitionName   = none                   PR                   none           none           accessorPR;
hydra.RegionPrms-enableGateway   = true                   true                 true           true           true;

hydra.RegionPrms-cacheListeners  = util.SummaryLogListener; // this is also a silence listener
hydra.PartitionPrms-names           = accessorPR           PR;
hydra.PartitionPrms-localMaxMemory  = 0                    default;
hydra.PartitionPrms-redundantCopies = 1                    1;

hydra.DiskStorePrms-names = diskStore1  diskStore2;
hydra.DiskStorePrms-autoCompact = true;  
hydra.DiskStorePrms-maxOplogSize = 1; // frequent new logs
hydra.DiskStorePrms-diskDirNum = ONEOF 1 2 3 4 5 FOENO;

diskRecovery.RecoveryPrms-numToLoad = 40; // each thread that runs the load task will create this many entries
diskRecovery.RecoveryPrms-useColocatedPRs = true; // even when true, only half the PRs are colocated so we still have coverage of non-colocated PRs
diskRecovery.RecoveryPrms-maxPRs = 18;
diskRecovery.RecoveryPrms-maxReplicates = 0; // for 6.5 we do not support consistency of persistent replicate regions, only PRs
