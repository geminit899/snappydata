//------------------------------------------------------------------------------
// TEST CONFIG
//------------------------------------------------------------------------------
//
//	sql/hdfs/hdfsMrRw.conf
//	    A=datastore datastoreHosts=4 datastoreVMsPerHost=1 datastoreThreadsPerVM=1
//	    B=accessor accessorHosts=2 accessorVMsPerHost=1 accessorThreadsPerVM=9
//	    locatorHosts = 1 locatorVMsPerHost =1 locatorThreadsPerVM = 1
//	    redundantCopies=1
//      testMultiTableJoin=false
//      testUniqueKeys=false
//	    securities=trade.securities:random
//	    customers=trade.customers:random
//	    networth=trade.networth:random
//	    portfolio=trade.portfolio:random
//	    sellorders=trade.sellorders:random
//	    buyorders=trade.buyorders:random
//	    txhistory=trade.txhistory:random
//	    companies=trade.companies:random
//      trades=trade.trades:random
//      employees=emp.employees:random      
//
//------------------------------------------------------------------------------
// INCLUDE FILES
//------------------------------------------------------------------------------

include $JTESTS/hydraconfig/hydraparams1.inc;
include $JTESTS/hydraconfig/gemfirexd/topology_accessor_locator.inc;

//------------------------------------------------------------------------------
// TEST DESCRIPTION
//------------------------------------------------------------------------------

hydra.Prms-testDescription=" GemFireXD test to verify MapReduce on read-write HDFS tables, operations from accessors. ";

hydra.VmPrms-extraClassPaths        += $GEMFIRE/../product-gfxd/lib/gemfirexd.jar;
hydra.VmPrms-extraClassPaths        += $GEMFIRE/../product-gfxd/lib/gemfirexd-client.jar;

hydra.VmPrms-extraVMArgs     += "-Dhoplog.janitor.interval.secs=30";
hydra.Prms-manageDerbyServer          = false;  
hydra.Prms-totalTaskTimeSec           = 300;
hydra.Prms-maxResultWaitSec           = 1800;
hydra.Prms-maxCloseTaskResultWaitSec  = 1800;
hydra.Prms-serialExecution            = false;	
hydra.Prms-alwaysDoEndTasks           = true;
hydra.Prms-checkTaskMethodsExist      = false;

sql.SQLPrms-supportDuplicateTables= true;

THREADGROUP locator
    totalThreads = fcn ${locatorHosts} * ${locatorVMsPerHost} * ${locatorThreadsPerVM} ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"locator\", ${locatorHosts}, true)"  ncf;

THREADGROUP datastoreThreads
    totalThreads = fcn ${${A}Hosts} * ${${A}VMsPerHost} * ${${A}ThreadsPerVM} ncf
    totalVMs     = fcn ${${A}Hosts} * ${${A}VMsPerHost} ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${A}\", ${${A}Hosts}, true)" ncf;

THREADGROUP ddlThread
    totalThreads = 1    
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${B}\", ${${B}Hosts}, true)" ncf;

THREADGROUP validatorThreads
    totalThreads = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
    totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${B}\", ${${B}Hosts}, true)" ncf;
    
THREADGROUP accessorThreads
    totalThreads = fcn ${${B}Hosts} * ${${B}VMsPerHost} * ${${B}ThreadsPerVM} 
                       - (${${B}Hosts} * ${${B}VMsPerHost} + 1) ncf
    totalVMs     = fcn ${${B}Hosts} * ${${B}VMsPerHost} ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${B}\", ${${B}Hosts}, true)" ncf;



STARTTASK taskClass = hdfs.HDFSUtil taskMethod = configureHadoopTask
          clientNames = locator1;

STARTTASK taskClass = hdfs.HDFSUtil taskMethod = startCluster
          clientNames = locator1;
               
INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_createGfxdLocatorTask
         threadGroups = locator;
         
INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_startGfxdLocatorTask
         threadGroups = locator;
         
INITTASK taskClass   = sql.SQLTest  taskMethod  = HydraTask_initializeFabricServer
         runMode = always
         threadGroups = locator, datastoreThreads, accessorThreads, ddlThread, validatorThreads;

INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_startFabricServer_Once
         runMode = always
         threadGroups = datastoreThreads, validatorThreads;	
	             	    
INITTASK taskClass = sql.SQLThinClientTest taskMethod = HydraTask_startNetworkServer
         runMode = always
	     threadGroups = datastoreThreads;	        
	     
INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_createGFESchemas
         threadGroups = ddlThread;
         
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_createDiskStores
         threadGroups = ddlThread;          
         
INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_createHDFSSTORE
         threadGroups = ddlThread;
	                                 
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_createGFETables
         threadGroups = ddlThread;           
	                
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_setHDFSEvictionObserver
         runMode = always
         threadGroups = datastoreThreads, validatorThreads;          
         	     
INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_createMRTables
         threadGroups = ddlThread;
	              
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_populateTables
       threadGroups = accessorThreads;       

INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_checkAsyncEventQueueEmptyForParallel
         threadGroups = datastoreThreads;         
              	
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_executeMR
	threadGroups = locator;
	         
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_verifyHdfsDataUsingMR
	threadGroups = validatorThreads;
	         	
TASK taskClass = sql.SQLTest taskMethod  = HydraTask_doDMLOp
     threadGroups = accessorThreads, ddlThread, validatorThreads;      

TASK      taskClass = sql.SQLTest taskMethod = HydraTask_flushQueuesHDFS
          threadGroups = ddlThread;

//TASK      taskClass = sql.SQLTest taskMethod = HydraTask_forceCompactionHDFS
          //threadGroups = ddlThread;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_flushQueuesHDFS
	  threadGroups = ddlThread;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_forceCompactionHDFS
	  threadGroups = ddlThread;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_checkAsyncEventQueueEmptyForParallel
         threadGroups = datastoreThreads;         
              
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_executeMR
	threadGroups = locator;
	         
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_verifyHdfsDataUsingMR
	threadGroups = validatorThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_dropAllTables
          threadGroups = ddlThread;          

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_dropHDFSSTORE
          threadGroups = ddlThread;	

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_shutDownDB
	      threadGroups = validatorThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_shutDownDB
	      threadGroups = datastoreThreads;     
     
ENDTASK taskClass = hdfs.HDFSUtil taskMethod = stopCluster
        clientNames = locator1;
             	 
            	 
sql.SQLPrms-testPartitionBy       = true;
sql.SQLPrms-withReplicatedTables  = false;
sql.SQLPrms-testUniqueKeys        = ${testUniqueKeys};
sql.SQLPrms-testMultiTableJoin    = ${testMultiTableJoin};
sql.SQLPrms-useGfxdConfig         = true;
sql.SQLPrms-hasHDFS               = true;
sql.SQLPrms-hdfsMrJob             = true;
sql.SQLPrms-initCustomersSizePerThread = 100; //make it 1 if we want to avoid bulk insert to customers.

sql.SQLPrms-hasNetworth = true;		//will create networth table - legacy flag
sql.SQLPrms-dmlOperations = ONEOF insert update update update query query query delete FOENO;

sql.SQLPrms-dmlTables = "trade.securities" "trade.customers" "trade.networth" "trade.portfolio" "trade.sellorders" "trade.buyorders" "trade.txhistory";
sql.SQLPrms-createSchemas = "create schema trade" "create schema emp" ;


 sql.SQLPrms-hdfsDDLExtn =
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "   
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "   
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "   
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "   
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "   
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "   
    " BUCKETS 10 HDFSSTORE (sqlhdfsStore) "           
    ;

sql.SQLPrms-createTablesStatements =
    "create table trade.securities (sec_id int not null, symbol varchar(10) not null, price decimal (30, 20), exchange varchar(10) not null, tid int, constraint sec_pk primary key (sec_id), constraint sec_uq unique (symbol, exchange), constraint exc_ch check (exchange in ('nasdaq', 'nye', 'amex', 'lse', 'fse', 'hkse', 'tse')))"
    "create table trade.customers (cid int not null, cust_name varchar(100), since date, addr varchar(100), tid int, primary key (cid))"
	"create table trade.networth (cid int not null, cash decimal (30, 20), securities decimal (30, 20), loanlimit int, availloan decimal (30, 20),  tid int, constraint netw_pk primary key (cid), constraint cust_newt_fk foreign key (cid) references trade.customers (cid) on delete restrict, constraint cash_ch check (cash>=0), constraint sec_ch check (securities >=0), constraint availloan_ck check (loanlimit>=availloan and availloan >=0))"
	"create table trade.portfolio (cid int not null, sid int not null, qty int not null, availQty int not null, subTotal decimal(30,20), tid int, constraint portf_pk primary key (cid, sid), constraint cust_fk foreign key (cid) references trade.customers (cid) on delete restrict, constraint sec_fk foreign key (sid) references trade.securities (sec_id), constraint qty_ck check (qty>=0), constraint avail_ch check (availQty>=0 and availQty<=qty))" 
	"create table trade.sellorders (oid int not null constraint orders_pk primary key, cid int, sid int, qty int, ask decimal (30, 20), order_time timestamp, status varchar(10) default 'open', tid int, constraint portf_fk foreign key (cid, sid) references trade.portfolio (cid, sid) on delete restrict, constraint status_ch check (status in ('cancelled', 'open', 'filled')))"
	"create table trade.buyorders(oid int not null constraint buyorders_pk primary key, cid int, sid int, qty int, bid decimal (30, 20), ordertime timestamp, status varchar(10), tid int, constraint bo_cust_fk foreign key (cid) references trade.customers (cid) on delete restrict, constraint bo_sec_fk foreign key (sid) references trade.securities (sec_id), constraint bo_qty_ck check (qty>=0))"
	"create table trade.txhistory(cid int, oid int, sid int, qty int, price decimal (30, 20), ordertime timestamp, type varchar(10), tid int,  constraint type_ch check (type in ('buy', 'sell')))" 
	"create table emp.employees (eid int not null constraint employees_pk primary key, emp_name varchar(100), deptid int , since date, addr varchar(100), picture blob ,  ssn varchar(9) , tid int)"
	"create table trade.trades (tid int, cid int, eid int, tradedate date, primary Key (tid), foreign key (cid) references trade.customers (cid), constraint emp_fk foreign key (eid) references emp.employees (eid))"	
	;
	
	
sql.SQLPrms-gfeDDLExtension = 	 
    "${securities}" 
    "${customers}"
    "${networth}"
    "${portfolio}"
    "${sellorders}"
    "${buyorders}" 
    "${txhistory}"    
    "${employees}"    
    "${trades}"    
    ;
   
sql.SQLPrms-redundancyClause =
    " REDUNDANCY ${redundantCopies}"   
    " REDUNDANCY ${redundantCopies}"   
    " REDUNDANCY ${redundantCopies}"  
    " REDUNDANCY ${redundantCopies}"  
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"   
    ;
    


// Hadoop Configuration
hydra.ConfigPrms-hadoopConfig     = hadoop;
hydra.HadoopPrms-names            = hadoop;
hydra.gemfirexd.HDFSStorePrms-hadoopName    = hadoop;

// HDFS Configuration - START  //
sql.SQLPrms-hasHDFS                        = true;
sql.hdfs.HDFSTestPrms-mapredVersion1         = ${mapredVersion1};
sql.hdfs.HDFSTestPrms-useRandomConfig         = false;
sql.hdfs.HDFSTestPrms-desiredMinorCompactions = 100;
sql.hdfs.HDFSTestPrms-desiredMajorCompactions = 2;
hydra.gemfirexd.GfxdConfigPrms-hdfsStoreConfig           = sqlhdfsStore;
hydra.gemfirexd.DiskStorePrms-names                  = hdfsDiskStore;
hydra.gemfirexd.HDFSStorePrms-names                  = sqlhdfsStore;
hydra.gemfirexd.HDFSStorePrms-homeDir                = gemfirexd_data;
hydra.gemfirexd.HDFSStorePrms-diskStoreName          = hdfsDiskStore;  //disk store name for overflow or persistence of HDFS event queue.
hydra.gemfirexd.HDFSStorePrms-batchSize            = 5;              //The size of batches sent to HDFS in MB. Default is 5 MB.
hydra.gemfirexd.HDFSStorePrms-batchTimeInterval      = 180000;           //Sets the batch time interval for a HDFS queue. This is the maximum time interval that can elapse before a batch of data from a bucket is sent to HDFS. time interval in milliseconds. Default is 5000 ms.
hydra.gemfirexd.HDFSStorePrms-blockCacheSize         = 10;             //Value is a percentage of the JVM heap. Default is 10.
hydra.gemfirexd.HDFSStorePrms-diskSynchronous        = true;           //Whether to enable persistence for an HDFS Event Queue, asynchronous writing to the disk if ASYNCHRONOUS. Default is true.
hydra.gemfirexd.HDFSStorePrms-writeOnlyFileRolloverInterval   = 3600;           //Default is 3600 (minutes?).
hydra.gemfirexd.HDFSStorePrms-maxQueueMemory     = 100;            //the maximum amount of memory (in MB) for an HDFS Event Queue. Default is 100MB.
hydra.gemfirexd.HDFSStorePrms-maxWriteOnlyFileSize            = 256;            //Default is 256.
hydra.gemfirexd.HDFSStorePrms-queuePersistent             = false;          //Default is false.
//hydra.gemfirexd.HDFSStorePrms-clientConfigFile = ;
//Minor Compaction
hydra.gemfirexd.HDFSStorePrms-minorCompact     = true;  //true if auto compaction is enabled. Default is true.
hydra.gemfirexd.HDFSStorePrms-minorCompactionThreads         = 10;    //maximum number of threads executing minor compaction. Default is 10.
hydra.gemfirexd.HDFSStorePrms-maxInputFileSize = 512;   //size threshold (in MB). A file larger than this size will not be considered for compaction. Default is 512MB.
hydra.gemfirexd.HDFSStorePrms-minInputFileCount  = 3;     //minimum count threshold. Compaction cycle will commence if the number of files to be compacted is more than this number. Default is 3.
hydra.gemfirexd.HDFSStorePrms-maxInputFileCount  = 10;    //maximum count threshold. Compaction cycle will not include more than the maximum number of files.  Default is 10.
//Major Compaction
hydra.gemfirexd.HDFSStorePrms-majorCompact         = true;  //true if auto major compaction is enabled. Default is true.
hydra.gemfirexd.HDFSStorePrms-majorCompactionInterval = 2;     //interval configuration that guides major compaction frequency in minutes. Default is 720 minutes.
hydra.gemfirexd.HDFSStorePrms-majorCompactionThreads   = 2;     //maximum number of threads executing major compaction. Default is 2.
// HDFS Configuration - END //

hydra.gemfirexd.DiskStorePrms-names = hdfsDiskStore;
sql.SQLPrms-createDiskStore = "create diskstore hdfsDiskStore 'hdfsDiskStore'" ;

hydra.gemfirexd.NetworkServerPrms-names = server;
hydra.gemfirexd.GfxdConfigPrms-networkServerConfig = server;
sql.SQLPrms-useGfxdConfig = true;

// HDFS dependencies - bug #48428
hydra.VmPrms-extraClassPaths +=
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${locatorHosts})" ncf
  ,       
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${${A}Hosts})" ncf
  ,       
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${${B}Hosts})" ncf
  ;       

hydra.gemfirexd.FabricServerPrms-conserveSockets = false; //due to #44545 & #47177
hydra.Prms-clientShutdownHook += sql.SQLTest dumpResults;

RANDOMINCLUDE $JTESTS/sql/offHeap.inc; // uses off-heap if include is randomly chosen
