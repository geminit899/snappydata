// secure hdfs (gfxd)
hydra.HadoopPrms-securityAuthentication = kerberosKinit;

// must specify hadoop distribution copied to /opt on secure hdfs enabled machine (like shdfs-01)
// because we write fails back into hadoop distribution directories
hydra.HadoopPrms-hadoopDist = /opt/hadoop-2.4.1-gphd-3.2.0.0-54;

// secure hadoop
hydra.gemfirexd.HDFSStorePrms-clientConfigFile = $JTESTS/sql/hdfs/hdfs-site-secure-clientConfig.xml;

// derby dependencies
hydra.VmPrms-extraClassPaths      +=   "/export/gcm/where/java/derby/derby-10.8.2.2/jars/insane/derby.jar";
hydra.VmPrms-extraClassPaths      +=   "/export/gcm/where/java/derby/derby-10.8.2.2/jars/insane/derbyclient.jar";
hydra.VmPrms-extraClassPaths      +=   "/export/gcm/where/java/derby/derby-10.8.2.2/jars/insane/derbytools.jar";
hydra.Prms-derbyServerClassPath    =   "/export/gcm/where/java/derby/derby-10.8.2.2/jars/insane/derbynet.jar";
hydra.Prms-extraDerbyServerVMArgs += " -Xmx1024m -Dderby.storage.pageCacheSize=32000 -Dderby.locks.waitTimeout=30 -Dderby.locks.deadlockTimeout=20 ";

// fix PermGen issues #49820
hydra.VmPrms-extraVMArgsSUN += "-XX:MaxPermSize=128m";

// use default configuration for hdfsstore
sql.hdfs.HDFSTestPrms-useRandomConfig = false;

// For running single machine configuration (gemfirexd members + HDFS cluster on same machine), simply comment out the following lines
//hydra.HadoopPrms-nameNodeHosts             = <host2>;
//hydra.HadoopPrms-nameNodeLogDrives         = a;
//hydra.HadoopPrms-nameNodeDataDrives        = b;
//hydra.HadoopPrms-resourceManagerLogDrive   = a;
//hydra.HadoopPrms-resourceManagerDataDrives = b;

//hydra.HadoopPrms-dataNodeHosts         = <host3> <host4>;
//hydra.HadoopPrms-dataNodeLogDrives     = a;
//hydra.HadoopPrms-dataNodeDataDrives    = b;
//hydra.HadoopPrms-nodeManagerLogDrives  = a;
//hydra.HadoopPrms-nodeManagerDataDrives = b;
