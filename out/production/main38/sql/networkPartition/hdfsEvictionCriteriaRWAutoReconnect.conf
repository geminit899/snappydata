//------------------------------------------------------------------------------
// INCLUDE FILES
//------------------------------------------------------------------------------

include $JTESTS/hydraconfig/hydraparams1.inc;
include $JTESTS/hydraconfig/gemfirexd/topology_3_locator.inc;

//------------------------------------------------------------------------------
// TEST DESCRIPTION
//------------------------------------------------------------------------------

hydra.Prms-testDescription=" GemFireXD test to verify eviction criteria on HDFS tables with operations from accessors and successful reconnect to DS and HDFS after network partition.";

hydra.GemFirePrms-enableNetworkPartitionDetection = true;
hydra.GemFirePrms-disableAutoReconnect = false;

hydra.VmPrms-extraClassPaths        += $GEMFIRE/../product-gfxd/lib/gemfirexd.jar;
hydra.VmPrms-extraClassPaths        += $JTESTS;

hydra.Prms-manageDerbyServer          = true;  
hydra.Prms-totalTaskTimeSec           = 300;
hydra.Prms-maxResultWaitSec           = 900;
hydra.Prms-maxCloseTaskResultWaitSec  = 1200;
hydra.Prms-serialExecution            = false;	
hydra.Prms-alwaysDoEndTasks           = true;
hydra.Prms-checkTaskMethodsExist      =false;

THREADGROUP locator
  totalThreads = fcn  ${locatorHosts} * ${locatorVMsPerHost} * ${locatorThreadsPerVM} ncf
  totalVMs     = fcn "(${locatorHosts} * ${locatorVMsPerHost})" ncf
  clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"locator\",
                                ${locatorHosts}, true)" ncf;

THREADGROUP survivingDatastoreThreads
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost} *  ${${A}ThreadsPerVM}) " ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\",
                                ${${A}Hosts}, true)" ncf;

THREADGROUP losingDatastoreThreads
            totalThreads = fcn "(${${B}Hosts} * ${${B}VMsPerHost} *  ${${B}ThreadsPerVM}) " ncf
            totalVMs     = fcn "(${${B}Hosts} * ${${B}VMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${B}\",
                                ${${B}Hosts}, true)" ncf;

THREADGROUP accessorThreads
    totalThreads = fcn ${${C}Hosts} * ${${C}VMsPerHost} * ${${C}ThreadsPerVM}
                       - (${${C}Hosts} * ${${C}VMsPerHost} + 1) ncf
    totalVMs     = fcn ${${C}Hosts} * ${${C}VMsPerHost} ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${C}\", ${${C}Hosts}, true)" ncf;

THREADGROUP ddlThread
    totalThreads = 1
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${C}\", ${${C}Hosts}, true)" ncf;

THREADGROUP validatorThreads
    totalThreads = fcn ${${C}Hosts} * ${${C}VMsPerHost} ncf
    totalVMs     = fcn ${${C}Hosts} * ${${C}VMsPerHost} ncf
    clientNames  = fcn "hydra.TestConfigFcns.generateNames (\"${C}\", ${${C}Hosts}, true)" ncf;

STARTTASK taskClass   = splitBrain.SplitBrainBB taskMethod = HydraTask_initialize 
          clientNames = locator1;                    

STARTTASK taskClass = hdfs.HDFSUtil taskMethod = configureHadoopTask
          clientNames = accessor1;

STARTTASK taskClass = hdfs.HDFSUtil taskMethod = startCluster
          clientNames = accessor1;

INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_createGfxdLocatorTask
         threadGroups = locator;
         
INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_startGfxdLocatorTask
         threadGroups = locator;
                                                              
INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_initializeFabricServer
         runMode = always
	 threadGroups = locator, survivingDatastoreThreads, losingDatastoreThreads, accessorThreads, ddlThread, validatorThreads;

INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_startFabricServer_Once
         runMode = always
         threadGroups = survivingDatastoreThreads, losingDatastoreThreads, validatorThreads;

INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_initializeNetworkPartitionSettings
         runMode = always
	 threadGroups = survivingDatastoreThreads, losingDatastoreThreads, accessorThreads, ddlThread, validatorThreads;

INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_createDiscDB
         threadGroups = accessorThreads;

INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_createDiscSchemas
         threadGroups = ddlThread;

INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_createDiscTables
         threadGroups = ddlThread;
  
INITTASK taskClass   = sql.SQLTest taskMethod  = HydraTask_createGFESchemas
         threadGroups = ddlThread;

INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_createDiskStores
         threadGroups = ddlThread; 

INITTASK taskClass = sql.SQLTest taskMethod = HydraTask_createHDFSSTORE
         threadGroups = ddlThread;      

INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_createGFETables
         threadGroups = ddlThread;
           
INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_setHDFSEvictionObserver
         runMode = always
         threadGroups = survivingDatastoreThreads, losingDatastoreThreads, validatorThreads;                             

INITTASK taskClass = sql.SQLTest taskMethod  = HydraTask_populateTables
       threadGroups = accessorThreads;

INITTASK     taskClass   = sql.SQLTest taskMethod  = HydraTask_verifyResultSets
  threadGroups = validatorThreads;

TASK     taskClass = sql.SQLTest taskMethod  = HydraTask_doDMLOp
         threadGroups = accessorThreads, ddlThread, validatorThreads;

TASK     taskClass = sql.SQLTest taskMethod = HydraTask_flushQueuesHDFS
         threadGroups = ddlThread;

TASK     taskClass = splitBrain.SBUtil taskMethod = dropConnection
         maxTimesToRun = 1
         startInterval = 60
         threadGroups = locator;

// can't do this check once disconnected, so it cannot be a closetask
TASK      taskClass   = sql.SQLTest taskMethod  =   HydraTask_checkForceDisconnect
          threadGroups = survivingDatastoreThreads, losingDatastoreThreads;

CLOSETASK  taskClass = sql.SQLTest taskMethod = HydraTask_verifyLosingPartition
           threadGroups = ddlThread;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_verifyDMLExecution
          threadGroups = accessorThreads;

CLOSETASK taskClass   = sql.SQLTest taskMethod  = HydraTask_verifyResultSets
          threadGroups = accessorThreads;

CLOSETASK taskClass = splitBrain.SBUtil taskMethod = restoreConnection
         threadGroups = locator;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_waitForReconnect
          threadGroups = losingDatastoreThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_verifyReconnect
          threadGroups = losingDatastoreThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_verifyDMLExecution
          threadGroups = losingDatastoreThreads, accessorThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_flushQueuesHDFS
          threadGroups = ddlThread
          ;

CLOSETASK taskClass = sql.SQLTest taskMethod = HydraTask_forceCompactionHDFS
          threadGroups = ddlThread
          ;
CLOSETASK     taskClass   = sql.SQLTest taskMethod  = HydraTask_verifyResultSets
  threadGroups = validatorThreads;	
  
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_verifyUniqeIndexData
          threadGroups = ddlThread , accessorThreads;  

// truncate all tables and read all data from HDFS. it should not return any data
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_clearTablesInOrder
          threadGroups = ddlThread , accessorThreads;
                    
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_verifyTotalRowsinTables
          threadGroups = validatorThreads;
          
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_populateTables
          threadGroups = accessorThreads;
          
// delete all tables and read all data from HDFS. it should not return any data
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_dropAllTables
          threadGroups = ddlThread;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_createGFETables
          threadGroups = ddlThread;  

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_clearTablesInOrder
          threadGroups = ddlThread , accessorThreads;
          
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_verifyTotalRowsinTables
          threadGroups = validatorThreads;

// populate tables again 
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_populateTables
          threadGroups = accessorThreads;

CLOSETASK     taskClass   = sql.SQLTest taskMethod  = HydraTask_verifyResultSets
  threadGroups = validatorThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_dropAllTables
          threadGroups = ddlThread;
          
CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_dropHDFSSTORE
          threadGroups = ddlThread;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_shutDownDB
	      threadGroups = validatorThreads;

CLOSETASK taskClass = sql.SQLTest taskMethod  = HydraTask_shutDownDB
	      threadGroups = survivingDatastoreThreads, losingDatastoreThreads;     
     
ENDTASK taskClass = hdfs.HDFSUtil taskMethod = stopCluster
        clientNames = accessor1;
             	 
sql.SQLPrms-testPartitionBy       = true;
sql.SQLPrms-withReplicatedTables  = false;
sql.SQLPrms-testUniqueKeys        = ${testUniqueKeys};
sql.SQLPrms-testMultiTableJoin    = ${testMultiTableJoin};
sql.SQLPrms-useGfxdConfig         = true;
sql.SQLPrms-initCustomersSizePerThread = 100; //make it 1 if we want to avoid bulk insert to customers.

sql.SQLPrms-hasNetworth = true;		//will create networth table - legacy flag
sql.SQLPrms-dmlOperations = ONEOF insert update update update query query query delete FOENO;

sql.SQLPrms-dmlTables = "trade.securities" "trade.customers" "trade.networth" "trade.portfolio" "trade.sellorders" "trade.buyorders" "trade.txhistory";
sql.SQLPrms-createSchemas = "create schema trade" "create schema emp" ;

sql.SQLPrms-createTablesStatements =
	"create table trade.securities (sec_id int not null, symbol varchar(10) not null, price decimal (30, 20), exchange varchar(10) not null, tid int, constraint sec_pk primary key (sec_id), constraint sec_uq unique (symbol, exchange), constraint exc_ch check (exchange in ('nasdaq', 'nye', 'amex', 'lse', 'fse', 'hkse', 'tse')))"
    "create table trade.customers (cid int not null, cust_name varchar(100), since date, addr varchar(100), tid int, primary key (cid))"
	"create table trade.networth (cid int not null, cash decimal (30, 20), securities decimal (30, 20), loanlimit int, availloan decimal (30, 20),  tid int, constraint netw_pk primary key (cid),  constraint cash_ch check (cash>=0), constraint sec_ch check (securities >=0), constraint availloan_ck check (loanlimit>=availloan and availloan >=0))"
	"create table trade.portfolio (cid int not null, sid int not null, qty int not null, availQty int not null, subTotal decimal(30,20), tid int, constraint portf_pk primary key (cid, sid), constraint qty_ck check (qty>=0), constraint avail_ch check (availQty>=0 and availQty<=qty))" 
	"create table trade.sellorders (oid int not null constraint orders_pk primary key, cid int, sid int, qty int, ask decimal (30, 20), order_time timestamp, status varchar(10) default 'open', tid int, constraint status_ch check (status in ('cancelled', 'open', 'filled')))"
	"create table trade.buyorders(oid int not null constraint buyorders_pk primary key, cid int, sid int, qty int, bid decimal (30, 20), ordertime timestamp, status varchar(10), tid int, constraint bo_qty_ck check (qty>=0))"
	"create table trade.txhistory(cid int, oid int, sid int, qty int, price decimal (30, 20), ordertime timestamp, type varchar(10), tid int,  constraint type_ch check (type in ('buy', 'sell')))"
	"create table emp.employees (eid int not null constraint employees_pk primary key, emp_name varchar(100), deptid int , since date, addr varchar(100), picture blob ,  ssn varchar(9) , tid int)"
	"create table trade.trades (tid int, cid int, eid int, tradedate date, primary Key (tid))"	
	;
	
sql.SQLPrms-redundancyClause =
    " REDUNDANCY ${redundantCopies}"  
    " REDUNDANCY ${redundantCopies}"  
    " REDUNDANCY ${redundantCopies}"   
    " REDUNDANCY ${redundantCopies}"  
    " REDUNDANCY ${redundantCopies}"  
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"
    " REDUNDANCY ${redundantCopies}"     
    ;
    
// trades and employees do not participate in HA tests
sql.SQLPrms-gfeDDLExtension = 	 
    "${securities}" 
    "${customers}"
    "${networth}"
    "${portfolio}"
    "${sellorders}"
    "${buyorders}"
    "${txhistory}"  
    "trade.trades:replicate"
    "emp.employees:replicate"
    ;
    
// no hdfsstore for trades and employees
sql.SQLPrms-hdfsDDLExtn =
    " EVICTION BY CRITERIA ( sec_id > 500) EVICT INCOMING HDFSSTORE (sqlhdfsStore)"   
    " EVICTION BY CRITERIA ( tid >= 20 ) EVICTION FREQUENCY 10 SECONDS HDFSSTORE (sqlhdfsStore)"
    " EVICTION BY CRITERIA ( cid > 100 ) EVICTION FREQUENCY 10 SECONDS HDFSSTORE (sqlhdfsStore)"    
    " EVICTION BY CRITERIA ( tid > 20 ) EVICT INCOMING HDFSSTORE (sqlhdfsStore)"    
    " EVICTION BY CRITERIA ( cid > 100 ) EVICT INCOMING HDFSSTORE (sqlhdfsStore)"
    " EVICTION BY CRITERIA ( cid > 100 ) EVICTION FREQUENCY 10 SECONDS HDFSSTORE (sqlhdfsStore)"
    " EVICTION BY CRITERIA ( price > 25 ) EVICTION FREQUENCY 10 SECONDS HDFSSTORE (sqlhdfsStore)"
    " "
    " "
    ;     

sql.hdfs.HDFSTestPrms-useRandomConfig = false;

// Hadoop Configuration
hydra.ConfigPrms-hadoopConfig     = hdfs;
hydra.HadoopPrms-names            = hdfs;
hydra.gemfirexd.HDFSStorePrms-hadoopName    = hdfs;

// HDFS Configuration
sql.SQLPrms-hasHDFS               = true;
sql.SQLPrms-supportDuplicateTables= false;

hydra.gemfirexd.GfxdConfigPrms-hdfsStoreConfig  = sqlhdfsStore;
hydra.gemfirexd.HDFSStorePrms-names         = sqlhdfsStore;
hydra.gemfirexd.HDFSStorePrms-homeDir       = gemfirexd_data;
hydra.gemfirexd.HDFSStorePrms-diskStoreName = hdfsDiskStore;
hydra.gemfirexd.DiskStorePrms-names = hdfsDiskStore;
sql.SQLPrms-createDiskStore = "create diskstore hdfsDiskStore 'hdfsDiskStore'" ;

// HDFS dependencies - bug #48428
hydra.VmPrms-extraClassPaths +=
  fcn "hydra.TestConfigFcns.duplicate(\"none\", ${locatorHosts}, true)" ncf
  ,
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${${A}Hosts})" ncf
  ,
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${${B}Hosts})" ncf
  ,
  fcn "hydra.HadoopPrms.getServerJars(\"$HADOOP_DIST\", ${${C}Hosts})" ncf
  ;

hydra.gemfirexd.FabricServerPrms-conserveSockets = false; //due to #44545 & #47177
hydra.gemfirexd.FabricServerPrms-enableNetworkPartitionDetection  = true;
hydra.gemfirexd.FabricServerPrms-disableAutoReconnect = false;
hydra.gemfirexd.FabricServerPrms-hostData = false true true false;

hydra.Prms-clientShutdownHook += sql.SQLTest dumpResults;

util.StopStartPrms-numVMsToStop = 1;

splitBrain.SplitBrainPrms-hostDescription1 = survivingDatastorehost1;
splitBrain.SplitBrainPrms-hostDescription2 = losingDatastorehost1;
splitBrain.SplitBrainPrms-losingPartition = losingDatastorehost1;


RANDOMINCLUDE $JTESTS/sql/offHeap.inc; // uses off-heap if include is randomly chosen
