hydra.Prms-testRequirement = "Test cdc in smart Connector mode with multi sqlserver and HA";
hydra.Prms-testDescription = "The test does the following:
A cluster is started in smart connector mode,then tables are created and populated.
Streaming app is executed on both the sql server instance ,followed by bulk delete to be in sync .
Then a validation job is executed ,which will record the number of rows in each table at snappy and sql server side in a file.
Then ingestion app will ingest some records in the sqlserver.
After which cdc streaming application is started and it keeps running in the bg.
The ingestion app is run in parallel , multithreaded pointlookup queries on the snappy cluster ,node HA will happen in specified time intervals.
Also after HA the streaming app is rescheduled .
These three operation will keep running for the time untill the totalTaskTimeSec criteria is met ,upon which the streaming app is shut down.
And at the end validation is done ,to check if the changes in the sqlserver has been reflected in the snappy cluster.";

INCLUDE $JTESTS/io/snappydata/hydra/cdcConnector/cdcConnectorMultiSqlServerInstanceTest.conf;
INCLUDE $JTESTS/io/snappydata/hydra/cdcConnector/snappyCustomizedHA.inc;

TASK        taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.app.JavaCdcStreamingApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --total-executor-cores=&{coresPerStrmApp} --conf spark.scheduler.mode=FAIR --conf spark.sql.defaultSizeInBytes=1000 --conf spark.driver.memory=10g --conf spark.executor.memory=4g --conf snappydata.store.memory-size=12g --conf spark.locality.wait=30 --conf spark.local.dir=/nfs/users/spillai/tmp1 --jars ${connectorJar},${driverJar},${testJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${connectionPropFile1} ${sourceDestFile1} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = "${pocJar}"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isCDCStream = true
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "JavaCdcStreamingApp1"
            threadGroups = snappyTaskThread1
            startInterval = 15480  //after every 4.30 hours retry submitting the streaming app
            endInterval   = 15480
            maxThreads = 1
            ;

TASK        taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.app.JavaCdcStreamingApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --total-executor-cores=&{coresPerStrmApp} --conf spark.scheduler.mode=FAIR --conf spark.sql.defaultSizeInBytes=1000 --conf spark.driver.memory=10g --conf spark.executor.memory=4g --conf snappydata.store.memory-size=12g --conf spark.locality.wait=30 --conf spark.local.dir=/nfs/users/spillai/tmp1 --jars ${connectorJar},${driverJar},${testJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${connectionPropFile2} ${sourceDestFile2} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = "${pocJar}"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isCDCStream = true
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "JavaCdcStreamingApp2"
            threadGroups = snappyTaskThread2
            startInterval = 15480  //after every 4.30 hours retry submitting the streaming app
            endInterval   = 15480
            maxThreads = 1
            ;

TASK        taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCIngestionApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar}  "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " ${insertQueryPath1} sqlServer1 "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "CDCIngestionApp2"
            threadGroups = snappyTaskThread3
            startInterval = 7200  //after every 2 hours do ingest
            endInterval   = 7200
            maxThreads = 1
            ;

TASK        taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCIngestionApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar}  "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " ${insertQueryPath2} sqlServer2 "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "CDCIngestionApp2"
            threadGroups = snappyTaskThread4
            startInterval = 7380  //after every 4.05 hours do ingest
            endInterval   = 7380
            maxThreads = 1
            ;

TASK        taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = HydraTask_runConcurrencyJob
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-threadCnt = ${threadCnt}
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-dataLocation = ${queryFilePath}
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isPointLookUP = true
            threadGroups = snappyTaskThread5
            startInterval = 10800  //after every 3 hour
            endInterval   = 10800
            maxThreads = 1;


