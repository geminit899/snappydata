hydra.Prms-testRequirement = "Test cdc in a long running cluster ";
hydra.Prms-testDescription = "The test does the following:
A cluster is started in smart connector mode,then tables are created and populated.
then a validtion job is executed ,which will record the number of rows in each table at snappy and sql server side in a file.
Then ingestion app will ingest some records in the sqlserver.
After which cdc streaming application is started and it keeps running in the bg.
Now again ingestion app is run in parallel with the app,that does multithreaded pointlookup queries on the snappy cluster.
These three operation will keep running for the time untill the totalTaskTimeSec criteria is met ,upon which the streaming app is shut down.
And at the end validation is done ,to check if the changes in the sqlserver has been reflected in the snappy cluster.";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_1.inc;
INCLUDE $JTESTS/io/snappydata/hydra/cdcConnector/snappyCustomizedHA.inc;

INCLUDE $JTESTS/io/snappydata/hydra/cdcConnector/threadGroups.inc;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = initSnappyArtifacts
            runMode = always
            threadGroups = snappyThreads,snappyInitThread,snappyTaskThread1,snappyTaskThread2,snappyTaskThread3,snappyTaskThread4,snappyTaskThread5,snappyHAThread;

io.snappydata.hydra.cdcConnector.SnappyCDCPrms-initStartRange = fcn (${initStartRange}) ncf;

io.snappydata.hydra.cdcConnector.SnappyCDCPrms-initEndRange = fcn (${initEndRange}) ncf;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSQLScripts
            io.snappydata.hydra.cluster.SnappyPrms-sqlScriptNames = createAndLoadFewTables.sql
            io.snappydata.hydra.cluster.SnappyPrms-dataLocation = ${dataFilesLocation}
            threadGroups = snappyInitThread;

INITTASK    taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.app.JavaCdcStreamingApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --total-executor-cores=${coresPerStrmApp} --jars ${connectorJar},${driverJar},${testJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${connectionPropFile1} ${sourceDestFile1} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = "${pocJar}"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isCDCStream = true
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "JavaCdcStreamingApp"
            threadGroups = snappyInitThread
            ;

INITTASK    taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCPerfSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " 1 ${deleteQFilePath} false 0 true false false ${initStartRange} sqlServer1"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "BulkDeleteApp"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyInitThread;

INITTASK    taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCValidationApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " ${tableListPath1} 1 false ${dataBaseName} sqlServer1 CDCValidationAppStrm"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "CDCValidationAppStrm"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyInitThread
            ;

INITTASK    taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCIngestionApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " ${initStartRange} ${initEndRange} ${insertQueryPath1} sqlServer1"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "CDCIngestionApp1"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyInitThread;


TASK    taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.app.JavaCdcStreamingApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --total-executor-cores=30 --conf spark.scheduler.mode=FAIR --conf spark.sql.defaultSizeInBytes=1000 --conf spark.driver.memory=10g --conf spark.executor.memory=4g --conf snappydata.store.memory-size=12g --conf spark.locality.wait=30 --conf spark.local.dir=/nfs/users/spillai/tmp1 --jars ${connectorJar},${driverJar},${testJar} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${connectionPropFile1} ${sourceDestFile1} "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = "${pocJar}"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isCDCStream = true
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "JavaCdcStreamingApp"
            threadGroups = snappyThreads
            startInterval = 16020  //after every 4.45 hours retry submitting the streaming app
            endInterval   = 16020
            maxThreads = 1
            ;

TASK        taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCIngestionApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar}  "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " ${insertQueryPath1} sqlServer1 "
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "CDCIngestionApp2"
            threadGroups = snappyTaskThread1
            startInterval = 14760  //after every 4.1 hours do ingest
            endInterval   = 14760
            maxThreads = 1
            ;

TASK        taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = HydraTask_runConcurrencyJob
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-threadCnt = ${threadCnt}
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-dataLocation = ${queryFilePath}
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isPointLookUP = true
            threadGroups = snappyTaskThread2
            startInterval = 7200  //after every 2 hour
            endInterval   = 7200
            maxThreads = 1;

TASK        taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = performHA
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeInfoforHA="dev7 -heap-size=10g -memory-size=80g"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-snappyFileLoc = "/export/dev11a/users/spillai/snappydata/build-artifacts/scala-2.11/snappy"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-nodeType = servers
            threadGroups = snappyHAThread
            startInterval = 7200  //after every 2 hour
            endInterval   = 7200
            maxThreads = 1;


CLOSETASK   taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = HydraTask_closeStreamingJob
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "JavaCdcStreamingApp"
            threadGroups = snappyInitThread;

CLOSETASK   taskClass  = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.cdcConnector.CDCValidationApp
            io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --jars ${driverJar}  "
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = " ${tableListPath1} 2 false ${dataBaseName} sqlServer1 CDCValidationAppStrm"
            io.snappydata.hydra.cdcConnector.SnappyCDCPrms-appName= "CDCValidationAppStrm"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyInitThread
            ;

hydra.Prms-maxResultWaitSec = 172800; // 48 hours
hydra.Prms-totalTaskTimeSec = 172800; // 48 hours
io.snappydata.hydra.cluster.SnappyPrms-shufflePartitions = 6;
io.snappydata.hydra.cdcConnector.SnappyCDCPrms-isCDC = true;
io.snappydata.hydra.cluster.SnappyPrms-isStopMode = true;
io.snappydata.hydra.cluster.SnappyPrms-isLongRunningTest = true;
