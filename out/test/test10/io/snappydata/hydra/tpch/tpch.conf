INCLUDE $JTESTS/io/snappydata/hydra/northwind/startDualModeCluster.conf;

// create and load tables using snappyJob
INITTASK     taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
  io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.benchmark.snappy.tpch.TableCreationJob
  io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "dataLocation=${dataDir},Buckets_Order_Lineitem=${buckets_Order_Lineitem},Buckets_Cust_Part_PartSupp=${buckets_Cust_Part_PartSupp},Buckets_Nation_Region_Supp=${buckets_Nation_Region_Supp},Nation_Region_Supp_col=${Nation_Region_Supp_col},Redundancy=${Redundancy},Persistence=${Persistence},Persistence_Type=${Persistence_Type},NumberOfLoadStages=${NumberOfLoadStages},isParquet=${Parquet}"
  io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-cluster*tests.jar
  threadGroups = snappyThreads
  ;

TASK        taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.benchmark.snappy.tpch.QueryExecutionJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "queries=${queries},sparkSqlProps=${sparkSqlProperties},isDynamic=${IsDynamic},resultCollection=${ResultCollection},warmUpIterations=${WarmupRuns},actualRuns=${AverageRuns},threadNumber=${threadNumber}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-cluster*tests.jar
            maxThreads = 1
            maxTimesToRun = 1
            threadGroups = leadThreads;


INCLUDE $JTESTS/io/snappydata/hydra/northwind/stopDualModeCluster.conf;

hydra.Prms-totalTaskTimeSec           = 120;
hydra.Prms-maxResultWaitSec           = 1200;
