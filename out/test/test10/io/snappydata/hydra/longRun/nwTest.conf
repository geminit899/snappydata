hydra.Prms-testRequirement = "Test for long running scenario using north
 wind  schema, data and queries";
hydra.Prms-testDescription = "This test uses the same cluster started using startDualModeCluster
 test. Test runs the spark App for creating and loading data in column tables using
 northwind schema and data. It then executes the snappy job, spark app and sql script in parallel.
 Snappy job executes and validate the northwind queries on the tables created and loaded through
 split mode along with lead, locator and server node HA.
 Spark app executes and validate the northwind queries on the tables created and loaded through
 split mode along with lead, locator and server node HA.
 sql script only executes the northwind queries on the tables created and loaded through split
 mode along with lead, locator and server node HA.";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_1.inc;

THREADGROUP snappyThreads
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost} *  ${${A}ThreadsPerVM}) -1 " ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\",
                                ${${A}Hosts}, true)" ncf;

THREADGROUP snappySingleThread
            totalThreads = 1
            totalVMs     = 1
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\",
                                ${${A}Hosts}, true)" ncf;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_initializeSnappyTest
            runMode = always
            threadGroups = snappyThreads, snappySingleThread;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSQLScripts
            io.snappydata.hydra.cluster.SnappyPrms-sqlScriptNames = create_and_load_columnTables_persistent.sql
            io.snappydata.hydra.cluster.SnappyPrms-dataLocation = ${dataFilesLocation}
            threadGroups = snappySingleThread
            ;

TASK        taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.northwind.ValidateNWQueriesJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer =
                        "dataFilesLocation=${dataFilesLocation},tableType=${tableType},fullResultSetValidation=${fullResultSetValidation},isSmokeRun=${isSmokeRun},numRowsValidation=${numRowsValidation}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads
            maxThreads = 1
            maxTimesToRun = 1;

TASK        taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.northwind.ValidateNWQueriesApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${dataFilesLocation} ${tableType} ${fullResultSetValidation} ${isSmokeRun} ${numRowsValidation}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            maxThreads = 1
            maxTimesToRun = 1
            threadGroups = snappyThreads;

TASK        taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSQLScripts
            io.snappydata.hydra.cluster.SnappyPrms-sqlScriptNames = nw_queries_startUp.sql
            threadGroups = snappyThreads
            ;

hydra.Prms-totalTaskTimeSec           = 3600;
hydra.Prms-maxResultWaitSec           = 3600;

hydra.Prms-maxCloseTaskResultWaitSec  = 3600;

io.snappydata.hydra.cluster.SnappyPrms-isStopMode = true;
io.snappydata.hydra.cluster.SnappyPrms-isLongRunningTest = true;
io.snappydata.hydra.cluster.SnappyPrms-useSmartConnectorMode = true;

io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar;