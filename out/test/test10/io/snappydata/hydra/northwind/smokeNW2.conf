hydra.Prms-testRequirement = "Test to verify Partitioned Row tables functionality using north
 wind  schema, data and queries";
hydra.Prms-testDescription = "This test uses the same cluster started using startDualModeCluster
 test. Test runs the spark App for creating and loading data in Partitioned row tables using
 northwind schema and data. It then executes the snappy job and sql script in parallel.
 Snappy job executes and validate the northwind queries on the tables created and loaded through
 split mode.
 sql script only executes the northwind queries on the tables created and loaded through split
 mode.";

INCLUDE $JTESTS/hydraconfig/hydraparams1.inc;
INCLUDE $JTESTS/hydraconfig/topology_1.inc;

THREADGROUP snappyThreads
            totalThreads = fcn "(${${A}Hosts} * ${${A}VMsPerHost} *  ${${A}ThreadsPerVM}) -1 " ncf
            totalVMs     = fcn "(${${A}Hosts} * ${${A}VMsPerHost})" ncf
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\",
                                ${${A}Hosts}, true)" ncf;

THREADGROUP snappySingleThread
            totalThreads = 1
            totalVMs     = 1
            clientNames  = fcn "hydra.TestConfigFcns.generateNames(\"${A}\",
                                ${${A}Hosts}, true)" ncf;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_initializeSnappyTest
            runMode = always
            threadGroups = snappyThreads, snappySingleThread;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.northwind.CreateAndLoadNWTablesSparkApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${dataFilesLocation} ${tableType} ${createLargeOrderTable} "
            threadGroups = snappySingleThread
            ;

TASK        taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.northwind.ValidateNWQueriesJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer =
                        "dataFilesLocation=${dataFilesLocation},tableType=${tableType},fullResultSetValidation=${fullResultSetValidation},isSmokeRun=${isSmokeRun},numRowsValidation=${numRowsValidation}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads
            maxThreads = 1
            maxTimesToRun = 1;

TASK        taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSQLScripts
            io.snappydata.hydra.cluster.SnappyPrms-sqlScriptNames = nw_queries.sql
            threadGroups = snappySingleThread
            //maxThreads = 1
            ;

hydra.Prms-totalTaskTimeSec           = 60;
hydra.Prms-maxResultWaitSec           = 600;

hydra.Prms-maxCloseTaskResultWaitSec  = 600;

io.snappydata.hydra.cluster.SnappyPrms-isStopMode = true;
io.snappydata.hydra.cluster.SnappyPrms-isLongRunningTest = true;

io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar;